{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xXGMcArQYe0V"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Adya2\\AppData\\Local\\Temp\\ipykernel_24128\\789677073.py:1: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout\n",
        "from keras.layers import BatchNormalization\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report\n",
        "import lightgbm as lgb\n",
        "from sklearn.feature_selection import mutual_info_classif\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ITitB5lZO6nh"
      },
      "outputs": [],
      "source": [
        "clinical = pd.read_csv('clinical.csv', index_col = 0 )\n",
        "#Read csv file in outer directory so that there is no change in the existing results and do not save but save as"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "ouOu9QDDRKEm",
        "outputId": "8fb17e72-2248-4ad3-ee6b-93931d8a6f00"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>PTID</th>\n",
              "      <th>RID</th>\n",
              "      <th>Phase</th>\n",
              "      <th>Group</th>\n",
              "      <th>PTGENDER_-4.0</th>\n",
              "      <th>PTGENDER_1.0</th>\n",
              "      <th>PTGENDER_2.0</th>\n",
              "      <th>PTHOME_-4.0</th>\n",
              "      <th>PTHOME_1.0</th>\n",
              "      <th>...</th>\n",
              "      <th>PHC_EXF</th>\n",
              "      <th>PHC_LAN</th>\n",
              "      <th>PTCOGBEG</th>\n",
              "      <th>AGE</th>\n",
              "      <th>PHC_VSP</th>\n",
              "      <th>PTDOBYY</th>\n",
              "      <th>PHC_MEM</th>\n",
              "      <th>VISDATE</th>\n",
              "      <th>PTDOB</th>\n",
              "      <th>PTADDX</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>002_S_0295</td>\n",
              "      <td>295</td>\n",
              "      <td>ADNI1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>...</td>\n",
              "      <td>0.554</td>\n",
              "      <td>0.272</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>84.9363</td>\n",
              "      <td>0.483</td>\n",
              "      <td>1921.0</td>\n",
              "      <td>1.357</td>\n",
              "      <td>2006-04-04</td>\n",
              "      <td>06/1921</td>\n",
              "      <td>-4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>002_S_0413</td>\n",
              "      <td>413</td>\n",
              "      <td>ADNI1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>...</td>\n",
              "      <td>1.480</td>\n",
              "      <td>2.594</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>76.9528</td>\n",
              "      <td>-4.000</td>\n",
              "      <td>1929.0</td>\n",
              "      <td>1.287</td>\n",
              "      <td>2006-04-06</td>\n",
              "      <td>12/1929</td>\n",
              "      <td>-4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>002_S_0559</td>\n",
              "      <td>559</td>\n",
              "      <td>ADNI1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>...</td>\n",
              "      <td>1.176</td>\n",
              "      <td>1.041</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>80.5284</td>\n",
              "      <td>-4.000</td>\n",
              "      <td>1927.0</td>\n",
              "      <td>0.768</td>\n",
              "      <td>2006-05-11</td>\n",
              "      <td>01/1927</td>\n",
              "      <td>-4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>002_S_0619</td>\n",
              "      <td>619</td>\n",
              "      <td>ADNI1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.509</td>\n",
              "      <td>0.116</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>78.0315</td>\n",
              "      <td>0.264</td>\n",
              "      <td>1928.0</td>\n",
              "      <td>-1.259</td>\n",
              "      <td>2006-05-18</td>\n",
              "      <td>12/1928</td>\n",
              "      <td>-4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>002_S_0685</td>\n",
              "      <td>685</td>\n",
              "      <td>ADNI1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>...</td>\n",
              "      <td>0.111</td>\n",
              "      <td>1.170</td>\n",
              "      <td>-4.0</td>\n",
              "      <td>92.7228</td>\n",
              "      <td>-4.000</td>\n",
              "      <td>1916.0</td>\n",
              "      <td>0.149</td>\n",
              "      <td>2006-06-22</td>\n",
              "      <td>11/1916</td>\n",
              "      <td>-4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 120 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   index        PTID  RID  Phase  Group  PTGENDER_-4.0  PTGENDER_1.0  \\\n",
              "0      0  002_S_0295  295  ADNI1    0.0          False          True   \n",
              "1      1  002_S_0413  413  ADNI1    0.0          False         False   \n",
              "2      2  002_S_0559  559  ADNI1    0.0          False          True   \n",
              "3      3  002_S_0619  619  ADNI1    2.0          False          True   \n",
              "4      4  002_S_0685  685  ADNI1    0.0          False         False   \n",
              "\n",
              "   PTGENDER_2.0  PTHOME_-4.0  PTHOME_1.0  ...  PHC_EXF  PHC_LAN  PTCOGBEG  \\\n",
              "0         False        False        True  ...    0.554    0.272      -4.0   \n",
              "1          True        False        True  ...    1.480    2.594      -4.0   \n",
              "2         False        False        True  ...    1.176    1.041      -4.0   \n",
              "3         False        False       False  ...   -0.509    0.116      -4.0   \n",
              "4          True        False        True  ...    0.111    1.170      -4.0   \n",
              "\n",
              "       AGE  PHC_VSP  PTDOBYY  PHC_MEM     VISDATE    PTDOB  PTADDX  \n",
              "0  84.9363    0.483   1921.0    1.357  2006-04-04  06/1921    -4.0  \n",
              "1  76.9528   -4.000   1929.0    1.287  2006-04-06  12/1929    -4.0  \n",
              "2  80.5284   -4.000   1927.0    0.768  2006-05-11  01/1927    -4.0  \n",
              "3  78.0315    0.264   1928.0   -1.259  2006-05-18  12/1928    -4.0  \n",
              "4  92.7228   -4.000   1916.0    0.149  2006-06-22  11/1916    -4.0  \n",
              "\n",
              "[5 rows x 120 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clinical.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "B9uFUn-wT6oL"
      },
      "outputs": [],
      "source": [
        "boolean_cols = [col for col in clinical.columns if clinical[col].dtype == 'bool']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Eihw3eqzTYYi"
      },
      "outputs": [],
      "source": [
        "for i in boolean_cols:\n",
        "  clinical[i] = clinical[i].astype(int)\n",
        "X = clinical.drop(['Group','PTID','Phase', 'VISDATE','RID','index'], axis=1)\n",
        "y = clinical['Group']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vsIH4sR2pA7H"
      },
      "outputs": [],
      "source": [
        "X['PTDOB'] = X['PTDOB'].astype(str)\n",
        "#X = X.drop(X.index[2938])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fDSGGg5nUGBC"
      },
      "outputs": [],
      "source": [
        "X['PTDOB'] = X['PTDOB'].apply(lambda x: int(x[:2]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z06vonx7fUUG",
        "outputId": "b3adbaab-2870-4fd7-ad4f-0f27fafb3d10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PTGENDER_-4.0       0\n",
              "PTGENDER_1.0     1128\n",
              "PTGENDER_2.0     1104\n",
              "PTHOME_-4.0         0\n",
              "PTHOME_1.0       1707\n",
              "                 ... \n",
              "PTTLANG_1.0      2199\n",
              "PTTLANG_2.0        33\n",
              "NXCONSCI_-4.0      16\n",
              "NXCONSCI_1.0     2210\n",
              "NXCONSCI_2.0        6\n",
              "Length: 105, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[boolean_cols].sum() #106 boolean cols ---> only 10 non-bool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "#y=y.drop(y.index[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OBMT0og8gBf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PHC_MEM          0.503768\n",
            "PTCOGBEG         0.323648\n",
            "PTADDX           0.235206\n",
            "PHC_LAN          0.226221\n",
            "PHC_EXF          0.205060\n",
            "                   ...   \n",
            "NXNERVE_2.0      0.000000\n",
            "NXPLANTA_1.0     0.000000\n",
            "NXPLANTA_2.0     0.000000\n",
            "PTMARRY_-4.0     0.000000\n",
            "PTGENDER_-4.0    0.000000\n",
            "Name: MI Scores, Length: 114, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def make_mi_scores(X, y):\n",
        "    #X=X.drop(columns=['Subject'])\n",
        "    mi_scores = mutual_info_classif(X, y)\n",
        "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
        "    mi_scores = mi_scores.sort_values(ascending=False)\n",
        "    return mi_scores\n",
        "\n",
        "mi_scores = make_mi_scores(X, y)\n",
        "print(mi_scores[::])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = list(mi_scores[:20:].index)\n",
        "\n",
        "X=X.loc[:, features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Q1_YzJpPiZTv"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_scaled = (X - X.mean(axis=0)) / X.std(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "#features = list(mi_scores[:20:].index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "#X=X.loc[:, features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PHC_MEM</th>\n",
              "      <th>PTCOGBEG</th>\n",
              "      <th>PTADDX</th>\n",
              "      <th>PHC_LAN</th>\n",
              "      <th>PHC_EXF</th>\n",
              "      <th>PHC_VSP</th>\n",
              "      <th>NXTENDON_2.0</th>\n",
              "      <th>PTGENDER_2.0</th>\n",
              "      <th>AGE</th>\n",
              "      <th>NXVISUAL_1.0</th>\n",
              "      <th>NXCONSCI_2.0</th>\n",
              "      <th>NXVISUAL_-4.0</th>\n",
              "      <th>PTHAND_-4.0</th>\n",
              "      <th>NXTREMOR_1.0</th>\n",
              "      <th>NXTENDON_-4.0</th>\n",
              "      <th>PTHOME_-4.0</th>\n",
              "      <th>NXGAIT_-4.0</th>\n",
              "      <th>NXOTHER_2.0</th>\n",
              "      <th>NXPLANTA_-4.0</th>\n",
              "      <th>PTTLANG_2.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.342147</td>\n",
              "      <td>-0.978146</td>\n",
              "      <td>-1.331988</td>\n",
              "      <td>0.386929</td>\n",
              "      <td>0.588460</td>\n",
              "      <td>1.313698</td>\n",
              "      <td>-0.407517</td>\n",
              "      <td>-0.989083</td>\n",
              "      <td>1.532499</td>\n",
              "      <td>0.249646</td>\n",
              "      <td>-0.051906</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.029941</td>\n",
              "      <td>0.365391</td>\n",
              "      <td>-0.090147</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.224344</td>\n",
              "      <td>-0.141777</td>\n",
              "      <td>-0.122475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.257840</td>\n",
              "      <td>-0.978146</td>\n",
              "      <td>-1.331988</td>\n",
              "      <td>1.628601</td>\n",
              "      <td>1.085774</td>\n",
              "      <td>-0.936509</td>\n",
              "      <td>-0.407517</td>\n",
              "      <td>1.010585</td>\n",
              "      <td>0.475165</td>\n",
              "      <td>0.249646</td>\n",
              "      <td>-0.051906</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.029941</td>\n",
              "      <td>-2.735569</td>\n",
              "      <td>-0.090147</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.224344</td>\n",
              "      <td>-0.141777</td>\n",
              "      <td>-0.122475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.632764</td>\n",
              "      <td>-0.978146</td>\n",
              "      <td>-1.331988</td>\n",
              "      <td>0.798146</td>\n",
              "      <td>0.922509</td>\n",
              "      <td>-0.936509</td>\n",
              "      <td>-0.407517</td>\n",
              "      <td>-0.989083</td>\n",
              "      <td>0.948717</td>\n",
              "      <td>0.249646</td>\n",
              "      <td>-0.051906</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.029941</td>\n",
              "      <td>0.365391</td>\n",
              "      <td>-0.090147</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.224344</td>\n",
              "      <td>-0.141777</td>\n",
              "      <td>-0.122475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.808525</td>\n",
              "      <td>-0.978146</td>\n",
              "      <td>-1.331988</td>\n",
              "      <td>0.303509</td>\n",
              "      <td>0.017569</td>\n",
              "      <td>1.203773</td>\n",
              "      <td>-0.407517</td>\n",
              "      <td>-0.989083</td>\n",
              "      <td>0.618028</td>\n",
              "      <td>0.249646</td>\n",
              "      <td>-0.051906</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.029941</td>\n",
              "      <td>0.365391</td>\n",
              "      <td>-0.090147</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>4.455437</td>\n",
              "      <td>-0.141777</td>\n",
              "      <td>-0.122475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.112750</td>\n",
              "      <td>-0.978146</td>\n",
              "      <td>-1.331988</td>\n",
              "      <td>0.867128</td>\n",
              "      <td>0.350544</td>\n",
              "      <td>-0.936509</td>\n",
              "      <td>-0.407517</td>\n",
              "      <td>1.010585</td>\n",
              "      <td>2.563742</td>\n",
              "      <td>0.249646</td>\n",
              "      <td>-0.051906</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.029941</td>\n",
              "      <td>-2.735569</td>\n",
              "      <td>-0.090147</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.224344</td>\n",
              "      <td>-0.141777</td>\n",
              "      <td>-0.122475</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    PHC_MEM  PTCOGBEG    PTADDX   PHC_LAN   PHC_EXF   PHC_VSP  NXTENDON_2.0  \\\n",
              "0  1.342147 -0.978146 -1.331988  0.386929  0.588460  1.313698     -0.407517   \n",
              "1  1.257840 -0.978146 -1.331988  1.628601  1.085774 -0.936509     -0.407517   \n",
              "2  0.632764 -0.978146 -1.331988  0.798146  0.922509 -0.936509     -0.407517   \n",
              "3 -1.808525 -0.978146 -1.331988  0.303509  0.017569  1.203773     -0.407517   \n",
              "4 -0.112750 -0.978146 -1.331988  0.867128  0.350544 -0.936509     -0.407517   \n",
              "\n",
              "   PTGENDER_2.0       AGE  NXVISUAL_1.0  NXCONSCI_2.0  NXVISUAL_-4.0  \\\n",
              "0     -0.989083  1.532499      0.249646     -0.051906      -0.084953   \n",
              "1      1.010585  0.475165      0.249646     -0.051906      -0.084953   \n",
              "2     -0.989083  0.948717      0.249646     -0.051906      -0.084953   \n",
              "3     -0.989083  0.618028      0.249646     -0.051906      -0.084953   \n",
              "4      1.010585  2.563742      0.249646     -0.051906      -0.084953   \n",
              "\n",
              "   PTHAND_-4.0  NXTREMOR_1.0  NXTENDON_-4.0  PTHOME_-4.0  NXGAIT_-4.0  \\\n",
              "0    -0.029941      0.365391      -0.090147          NaN    -0.084953   \n",
              "1    -0.029941     -2.735569      -0.090147          NaN    -0.084953   \n",
              "2    -0.029941      0.365391      -0.090147          NaN    -0.084953   \n",
              "3    -0.029941      0.365391      -0.090147          NaN    -0.084953   \n",
              "4    -0.029941     -2.735569      -0.090147          NaN    -0.084953   \n",
              "\n",
              "   NXOTHER_2.0  NXPLANTA_-4.0  PTTLANG_2.0  \n",
              "0    -0.224344      -0.141777    -0.122475  \n",
              "1    -0.224344      -0.141777    -0.122475  \n",
              "2    -0.224344      -0.141777    -0.122475  \n",
              "3     4.455437      -0.141777    -0.122475  \n",
              "4    -0.224344      -0.141777    -0.122475  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_scaled.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PPMx5-6t0nOc"
      },
      "outputs": [],
      "source": [
        "X_scaled.dropna(axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PHC_MEM</th>\n",
              "      <th>PTCOGBEG</th>\n",
              "      <th>PTADDX</th>\n",
              "      <th>PHC_LAN</th>\n",
              "      <th>PHC_EXF</th>\n",
              "      <th>PHC_VSP</th>\n",
              "      <th>NXTENDON_2.0</th>\n",
              "      <th>PTGENDER_2.0</th>\n",
              "      <th>AGE</th>\n",
              "      <th>NXVISUAL_1.0</th>\n",
              "      <th>NXCONSCI_2.0</th>\n",
              "      <th>NXVISUAL_-4.0</th>\n",
              "      <th>PTHAND_-4.0</th>\n",
              "      <th>NXTREMOR_1.0</th>\n",
              "      <th>NXTENDON_-4.0</th>\n",
              "      <th>NXGAIT_-4.0</th>\n",
              "      <th>NXOTHER_2.0</th>\n",
              "      <th>NXPLANTA_-4.0</th>\n",
              "      <th>PTTLANG_2.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.342147</td>\n",
              "      <td>-0.978146</td>\n",
              "      <td>-1.331988</td>\n",
              "      <td>0.386929</td>\n",
              "      <td>0.588460</td>\n",
              "      <td>1.313698</td>\n",
              "      <td>-0.407517</td>\n",
              "      <td>-0.989083</td>\n",
              "      <td>1.532499</td>\n",
              "      <td>0.249646</td>\n",
              "      <td>-0.051906</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.029941</td>\n",
              "      <td>0.365391</td>\n",
              "      <td>-0.090147</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.224344</td>\n",
              "      <td>-0.141777</td>\n",
              "      <td>-0.122475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.257840</td>\n",
              "      <td>-0.978146</td>\n",
              "      <td>-1.331988</td>\n",
              "      <td>1.628601</td>\n",
              "      <td>1.085774</td>\n",
              "      <td>-0.936509</td>\n",
              "      <td>-0.407517</td>\n",
              "      <td>1.010585</td>\n",
              "      <td>0.475165</td>\n",
              "      <td>0.249646</td>\n",
              "      <td>-0.051906</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.029941</td>\n",
              "      <td>-2.735569</td>\n",
              "      <td>-0.090147</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.224344</td>\n",
              "      <td>-0.141777</td>\n",
              "      <td>-0.122475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.632764</td>\n",
              "      <td>-0.978146</td>\n",
              "      <td>-1.331988</td>\n",
              "      <td>0.798146</td>\n",
              "      <td>0.922509</td>\n",
              "      <td>-0.936509</td>\n",
              "      <td>-0.407517</td>\n",
              "      <td>-0.989083</td>\n",
              "      <td>0.948717</td>\n",
              "      <td>0.249646</td>\n",
              "      <td>-0.051906</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.029941</td>\n",
              "      <td>0.365391</td>\n",
              "      <td>-0.090147</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.224344</td>\n",
              "      <td>-0.141777</td>\n",
              "      <td>-0.122475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.808525</td>\n",
              "      <td>-0.978146</td>\n",
              "      <td>-1.331988</td>\n",
              "      <td>0.303509</td>\n",
              "      <td>0.017569</td>\n",
              "      <td>1.203773</td>\n",
              "      <td>-0.407517</td>\n",
              "      <td>-0.989083</td>\n",
              "      <td>0.618028</td>\n",
              "      <td>0.249646</td>\n",
              "      <td>-0.051906</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.029941</td>\n",
              "      <td>0.365391</td>\n",
              "      <td>-0.090147</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>4.455437</td>\n",
              "      <td>-0.141777</td>\n",
              "      <td>-0.122475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.112750</td>\n",
              "      <td>-0.978146</td>\n",
              "      <td>-1.331988</td>\n",
              "      <td>0.867128</td>\n",
              "      <td>0.350544</td>\n",
              "      <td>-0.936509</td>\n",
              "      <td>-0.407517</td>\n",
              "      <td>1.010585</td>\n",
              "      <td>2.563742</td>\n",
              "      <td>0.249646</td>\n",
              "      <td>-0.051906</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.029941</td>\n",
              "      <td>-2.735569</td>\n",
              "      <td>-0.090147</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.224344</td>\n",
              "      <td>-0.141777</td>\n",
              "      <td>-0.122475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>-0.193444</td>\n",
              "      <td>1.446518</td>\n",
              "      <td>0.813980</td>\n",
              "      <td>0.326503</td>\n",
              "      <td>0.179223</td>\n",
              "      <td>0.778628</td>\n",
              "      <td>-0.407517</td>\n",
              "      <td>1.010585</td>\n",
              "      <td>0.872577</td>\n",
              "      <td>0.249646</td>\n",
              "      <td>-0.051906</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.029941</td>\n",
              "      <td>-2.735569</td>\n",
              "      <td>-0.090147</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>4.455437</td>\n",
              "      <td>7.050177</td>\n",
              "      <td>-0.122475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2228</th>\n",
              "      <td>1.083204</td>\n",
              "      <td>1.446518</td>\n",
              "      <td>0.813980</td>\n",
              "      <td>0.926484</td>\n",
              "      <td>0.733465</td>\n",
              "      <td>-0.936509</td>\n",
              "      <td>2.452788</td>\n",
              "      <td>1.010585</td>\n",
              "      <td>0.156793</td>\n",
              "      <td>0.249646</td>\n",
              "      <td>-0.051906</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.029941</td>\n",
              "      <td>0.365391</td>\n",
              "      <td>-0.090147</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.224344</td>\n",
              "      <td>7.050177</td>\n",
              "      <td>-0.122475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2229</th>\n",
              "      <td>0.459333</td>\n",
              "      <td>1.446518</td>\n",
              "      <td>0.813980</td>\n",
              "      <td>-1.897490</td>\n",
              "      <td>-1.857294</td>\n",
              "      <td>-0.936509</td>\n",
              "      <td>2.452788</td>\n",
              "      <td>-0.989083</td>\n",
              "      <td>1.247859</td>\n",
              "      <td>0.249646</td>\n",
              "      <td>-0.051906</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.029941</td>\n",
              "      <td>-2.735569</td>\n",
              "      <td>-0.090147</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.224344</td>\n",
              "      <td>7.050177</td>\n",
              "      <td>-0.122475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2230</th>\n",
              "      <td>-1.019653</td>\n",
              "      <td>-0.488995</td>\n",
              "      <td>0.813980</td>\n",
              "      <td>0.162872</td>\n",
              "      <td>-0.167715</td>\n",
              "      <td>1.050681</td>\n",
              "      <td>-0.407517</td>\n",
              "      <td>1.010585</td>\n",
              "      <td>0.233303</td>\n",
              "      <td>0.249646</td>\n",
              "      <td>-0.051906</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.029941</td>\n",
              "      <td>0.365391</td>\n",
              "      <td>-0.090147</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.224344</td>\n",
              "      <td>7.050177</td>\n",
              "      <td>-0.122475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2231</th>\n",
              "      <td>-1.482137</td>\n",
              "      <td>-0.489238</td>\n",
              "      <td>-0.898418</td>\n",
              "      <td>-1.897490</td>\n",
              "      <td>-1.857294</td>\n",
              "      <td>-0.936509</td>\n",
              "      <td>-0.407517</td>\n",
              "      <td>-0.989083</td>\n",
              "      <td>1.707637</td>\n",
              "      <td>0.249646</td>\n",
              "      <td>-0.051906</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>-0.029941</td>\n",
              "      <td>0.365391</td>\n",
              "      <td>-0.090147</td>\n",
              "      <td>-0.084953</td>\n",
              "      <td>4.455437</td>\n",
              "      <td>7.050177</td>\n",
              "      <td>-0.122475</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2232 rows × 19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       PHC_MEM  PTCOGBEG    PTADDX   PHC_LAN   PHC_EXF   PHC_VSP  \\\n",
              "0     1.342147 -0.978146 -1.331988  0.386929  0.588460  1.313698   \n",
              "1     1.257840 -0.978146 -1.331988  1.628601  1.085774 -0.936509   \n",
              "2     0.632764 -0.978146 -1.331988  0.798146  0.922509 -0.936509   \n",
              "3    -1.808525 -0.978146 -1.331988  0.303509  0.017569  1.203773   \n",
              "4    -0.112750 -0.978146 -1.331988  0.867128  0.350544 -0.936509   \n",
              "...        ...       ...       ...       ...       ...       ...   \n",
              "2227 -0.193444  1.446518  0.813980  0.326503  0.179223  0.778628   \n",
              "2228  1.083204  1.446518  0.813980  0.926484  0.733465 -0.936509   \n",
              "2229  0.459333  1.446518  0.813980 -1.897490 -1.857294 -0.936509   \n",
              "2230 -1.019653 -0.488995  0.813980  0.162872 -0.167715  1.050681   \n",
              "2231 -1.482137 -0.489238 -0.898418 -1.897490 -1.857294 -0.936509   \n",
              "\n",
              "      NXTENDON_2.0  PTGENDER_2.0       AGE  NXVISUAL_1.0  NXCONSCI_2.0  \\\n",
              "0        -0.407517     -0.989083  1.532499      0.249646     -0.051906   \n",
              "1        -0.407517      1.010585  0.475165      0.249646     -0.051906   \n",
              "2        -0.407517     -0.989083  0.948717      0.249646     -0.051906   \n",
              "3        -0.407517     -0.989083  0.618028      0.249646     -0.051906   \n",
              "4        -0.407517      1.010585  2.563742      0.249646     -0.051906   \n",
              "...            ...           ...       ...           ...           ...   \n",
              "2227     -0.407517      1.010585  0.872577      0.249646     -0.051906   \n",
              "2228      2.452788      1.010585  0.156793      0.249646     -0.051906   \n",
              "2229      2.452788     -0.989083  1.247859      0.249646     -0.051906   \n",
              "2230     -0.407517      1.010585  0.233303      0.249646     -0.051906   \n",
              "2231     -0.407517     -0.989083  1.707637      0.249646     -0.051906   \n",
              "\n",
              "      NXVISUAL_-4.0  PTHAND_-4.0  NXTREMOR_1.0  NXTENDON_-4.0  NXGAIT_-4.0  \\\n",
              "0         -0.084953    -0.029941      0.365391      -0.090147    -0.084953   \n",
              "1         -0.084953    -0.029941     -2.735569      -0.090147    -0.084953   \n",
              "2         -0.084953    -0.029941      0.365391      -0.090147    -0.084953   \n",
              "3         -0.084953    -0.029941      0.365391      -0.090147    -0.084953   \n",
              "4         -0.084953    -0.029941     -2.735569      -0.090147    -0.084953   \n",
              "...             ...          ...           ...            ...          ...   \n",
              "2227      -0.084953    -0.029941     -2.735569      -0.090147    -0.084953   \n",
              "2228      -0.084953    -0.029941      0.365391      -0.090147    -0.084953   \n",
              "2229      -0.084953    -0.029941     -2.735569      -0.090147    -0.084953   \n",
              "2230      -0.084953    -0.029941      0.365391      -0.090147    -0.084953   \n",
              "2231      -0.084953    -0.029941      0.365391      -0.090147    -0.084953   \n",
              "\n",
              "      NXOTHER_2.0  NXPLANTA_-4.0  PTTLANG_2.0  \n",
              "0       -0.224344      -0.141777    -0.122475  \n",
              "1       -0.224344      -0.141777    -0.122475  \n",
              "2       -0.224344      -0.141777    -0.122475  \n",
              "3        4.455437      -0.141777    -0.122475  \n",
              "4       -0.224344      -0.141777    -0.122475  \n",
              "...           ...            ...          ...  \n",
              "2227     4.455437       7.050177    -0.122475  \n",
              "2228    -0.224344       7.050177    -0.122475  \n",
              "2229    -0.224344       7.050177    -0.122475  \n",
              "2230    -0.224344       7.050177    -0.122475  \n",
              "2231     4.455437       7.050177    -0.122475  \n",
              "\n",
              "[2232 rows x 19 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "rwtDcXPDi4Hi",
        "outputId": "6cf91a2b-e252-4638-8fe9-1f1b6f2aadc6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PC1</th>\n",
              "      <th>PC2</th>\n",
              "      <th>PC3</th>\n",
              "      <th>PC4</th>\n",
              "      <th>PC5</th>\n",
              "      <th>PC6</th>\n",
              "      <th>PC7</th>\n",
              "      <th>PC8</th>\n",
              "      <th>PC9</th>\n",
              "      <th>PC10</th>\n",
              "      <th>PC11</th>\n",
              "      <th>PC12</th>\n",
              "      <th>PC13</th>\n",
              "      <th>PC14</th>\n",
              "      <th>PC15</th>\n",
              "      <th>PC16</th>\n",
              "      <th>PC17</th>\n",
              "      <th>PC18</th>\n",
              "      <th>PC19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.770569</td>\n",
              "      <td>-1.795769</td>\n",
              "      <td>-0.704237</td>\n",
              "      <td>-0.298823</td>\n",
              "      <td>-0.070293</td>\n",
              "      <td>0.612091</td>\n",
              "      <td>-0.548347</td>\n",
              "      <td>0.454063</td>\n",
              "      <td>0.342684</td>\n",
              "      <td>0.293667</td>\n",
              "      <td>0.378316</td>\n",
              "      <td>-0.558101</td>\n",
              "      <td>-0.494686</td>\n",
              "      <td>-0.065906</td>\n",
              "      <td>2.061160</td>\n",
              "      <td>-0.292019</td>\n",
              "      <td>-0.033139</td>\n",
              "      <td>-0.148656</td>\n",
              "      <td>-1.809770e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.328534</td>\n",
              "      <td>-1.277568</td>\n",
              "      <td>-1.466482</td>\n",
              "      <td>0.502768</td>\n",
              "      <td>0.494128</td>\n",
              "      <td>-0.428974</td>\n",
              "      <td>0.673616</td>\n",
              "      <td>-0.799487</td>\n",
              "      <td>-1.055636</td>\n",
              "      <td>1.563596</td>\n",
              "      <td>-1.688574</td>\n",
              "      <td>-0.311734</td>\n",
              "      <td>-2.389425</td>\n",
              "      <td>0.135006</td>\n",
              "      <td>0.178020</td>\n",
              "      <td>-0.049606</td>\n",
              "      <td>0.053201</td>\n",
              "      <td>0.393696</td>\n",
              "      <td>-2.927236e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.663819</td>\n",
              "      <td>-1.295387</td>\n",
              "      <td>-0.464862</td>\n",
              "      <td>-0.307156</td>\n",
              "      <td>0.357695</td>\n",
              "      <td>0.612665</td>\n",
              "      <td>-0.660085</td>\n",
              "      <td>0.479113</td>\n",
              "      <td>0.039347</td>\n",
              "      <td>1.088177</td>\n",
              "      <td>0.736485</td>\n",
              "      <td>0.280055</td>\n",
              "      <td>-1.522538</td>\n",
              "      <td>0.072187</td>\n",
              "      <td>0.339578</td>\n",
              "      <td>-0.022730</td>\n",
              "      <td>-0.014215</td>\n",
              "      <td>-0.068694</td>\n",
              "      <td>-1.730960e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.585333</td>\n",
              "      <td>-2.701526</td>\n",
              "      <td>1.245640</td>\n",
              "      <td>1.843878</td>\n",
              "      <td>-1.717556</td>\n",
              "      <td>-0.107609</td>\n",
              "      <td>0.866384</td>\n",
              "      <td>-1.071437</td>\n",
              "      <td>1.193222</td>\n",
              "      <td>1.622295</td>\n",
              "      <td>1.655577</td>\n",
              "      <td>1.073909</td>\n",
              "      <td>1.700696</td>\n",
              "      <td>-0.839251</td>\n",
              "      <td>0.189860</td>\n",
              "      <td>0.346160</td>\n",
              "      <td>-0.005908</td>\n",
              "      <td>0.150154</td>\n",
              "      <td>-2.006163e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.077044</td>\n",
              "      <td>-2.058518</td>\n",
              "      <td>0.095856</td>\n",
              "      <td>0.884738</td>\n",
              "      <td>0.148875</td>\n",
              "      <td>-0.183285</td>\n",
              "      <td>0.202972</td>\n",
              "      <td>-0.577484</td>\n",
              "      <td>-0.650233</td>\n",
              "      <td>1.401196</td>\n",
              "      <td>-1.372186</td>\n",
              "      <td>-2.057359</td>\n",
              "      <td>-2.381435</td>\n",
              "      <td>-0.047369</td>\n",
              "      <td>-0.328207</td>\n",
              "      <td>0.102378</td>\n",
              "      <td>0.058802</td>\n",
              "      <td>0.387489</td>\n",
              "      <td>2.529446e-16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
              "0 -0.770569 -1.795769 -0.704237 -0.298823 -0.070293  0.612091 -0.548347   \n",
              "1 -0.328534 -1.277568 -1.466482  0.502768  0.494128 -0.428974  0.673616   \n",
              "2 -0.663819 -1.295387 -0.464862 -0.307156  0.357695  0.612665 -0.660085   \n",
              "3 -0.585333 -2.701526  1.245640  1.843878 -1.717556 -0.107609  0.866384   \n",
              "4 -0.077044 -2.058518  0.095856  0.884738  0.148875 -0.183285  0.202972   \n",
              "\n",
              "        PC8       PC9      PC10      PC11      PC12      PC13      PC14  \\\n",
              "0  0.454063  0.342684  0.293667  0.378316 -0.558101 -0.494686 -0.065906   \n",
              "1 -0.799487 -1.055636  1.563596 -1.688574 -0.311734 -2.389425  0.135006   \n",
              "2  0.479113  0.039347  1.088177  0.736485  0.280055 -1.522538  0.072187   \n",
              "3 -1.071437  1.193222  1.622295  1.655577  1.073909  1.700696 -0.839251   \n",
              "4 -0.577484 -0.650233  1.401196 -1.372186 -2.057359 -2.381435 -0.047369   \n",
              "\n",
              "       PC15      PC16      PC17      PC18          PC19  \n",
              "0  2.061160 -0.292019 -0.033139 -0.148656 -1.809770e-16  \n",
              "1  0.178020 -0.049606  0.053201  0.393696 -2.927236e-16  \n",
              "2  0.339578 -0.022730 -0.014215 -0.068694 -1.730960e-16  \n",
              "3  0.189860  0.346160 -0.005908  0.150154 -2.006163e-17  \n",
              "4 -0.328207  0.102378  0.058802  0.387489  2.529446e-16  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Create principal components\n",
        "pca = PCA()\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
        "X_pca = pd.DataFrame(X_pca, columns=component_names)\n",
        "\n",
        "X_pca.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "BLfR46XJjO-x",
        "outputId": "c7038226-5d6f-41a7-d037-b6329f0f9d4e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PC1</th>\n",
              "      <th>PC2</th>\n",
              "      <th>PC3</th>\n",
              "      <th>PC4</th>\n",
              "      <th>PC5</th>\n",
              "      <th>PC6</th>\n",
              "      <th>PC7</th>\n",
              "      <th>PC8</th>\n",
              "      <th>PC9</th>\n",
              "      <th>PC10</th>\n",
              "      <th>PC11</th>\n",
              "      <th>PC12</th>\n",
              "      <th>PC13</th>\n",
              "      <th>PC14</th>\n",
              "      <th>PC15</th>\n",
              "      <th>PC16</th>\n",
              "      <th>PC17</th>\n",
              "      <th>PC18</th>\n",
              "      <th>PC19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PHC_MEM</th>\n",
              "      <td>0.001072</td>\n",
              "      <td>0.359827</td>\n",
              "      <td>-0.389360</td>\n",
              "      <td>0.080056</td>\n",
              "      <td>0.070478</td>\n",
              "      <td>-0.001679</td>\n",
              "      <td>-0.038301</td>\n",
              "      <td>0.082303</td>\n",
              "      <td>-0.156810</td>\n",
              "      <td>0.169082</td>\n",
              "      <td>0.021889</td>\n",
              "      <td>0.018530</td>\n",
              "      <td>-0.263598</td>\n",
              "      <td>0.023218</td>\n",
              "      <td>0.729877</td>\n",
              "      <td>-0.206129</td>\n",
              "      <td>-0.004861</td>\n",
              "      <td>0.006753</td>\n",
              "      <td>5.091890e-18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PTCOGBEG</th>\n",
              "      <td>0.036229</td>\n",
              "      <td>0.484679</td>\n",
              "      <td>-0.211937</td>\n",
              "      <td>0.207516</td>\n",
              "      <td>-0.051583</td>\n",
              "      <td>0.039036</td>\n",
              "      <td>-0.014900</td>\n",
              "      <td>0.104569</td>\n",
              "      <td>0.207922</td>\n",
              "      <td>-0.118194</td>\n",
              "      <td>-0.039418</td>\n",
              "      <td>-0.187855</td>\n",
              "      <td>0.123804</td>\n",
              "      <td>-0.033639</td>\n",
              "      <td>-0.049528</td>\n",
              "      <td>0.739919</td>\n",
              "      <td>0.001828</td>\n",
              "      <td>-0.003383</td>\n",
              "      <td>3.791831e-18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PTADDX</th>\n",
              "      <td>0.073074</td>\n",
              "      <td>0.482489</td>\n",
              "      <td>-0.132886</td>\n",
              "      <td>0.189855</td>\n",
              "      <td>-0.064794</td>\n",
              "      <td>0.092312</td>\n",
              "      <td>-0.006305</td>\n",
              "      <td>0.109903</td>\n",
              "      <td>0.211397</td>\n",
              "      <td>-0.165021</td>\n",
              "      <td>-0.116566</td>\n",
              "      <td>-0.140856</td>\n",
              "      <td>0.226397</td>\n",
              "      <td>-0.124883</td>\n",
              "      <td>-0.337585</td>\n",
              "      <td>-0.629758</td>\n",
              "      <td>-0.004443</td>\n",
              "      <td>0.023345</td>\n",
              "      <td>5.789338e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PHC_LAN</th>\n",
              "      <td>-0.187430</td>\n",
              "      <td>-0.237548</td>\n",
              "      <td>-0.566755</td>\n",
              "      <td>0.035224</td>\n",
              "      <td>0.004257</td>\n",
              "      <td>0.006745</td>\n",
              "      <td>0.054099</td>\n",
              "      <td>0.041101</td>\n",
              "      <td>0.007637</td>\n",
              "      <td>0.053582</td>\n",
              "      <td>0.050989</td>\n",
              "      <td>0.082257</td>\n",
              "      <td>-0.089286</td>\n",
              "      <td>-0.015991</td>\n",
              "      <td>-0.238164</td>\n",
              "      <td>0.019281</td>\n",
              "      <td>0.013884</td>\n",
              "      <td>0.709577</td>\n",
              "      <td>-2.635904e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PHC_EXF</th>\n",
              "      <td>-0.185009</td>\n",
              "      <td>-0.223970</td>\n",
              "      <td>-0.572115</td>\n",
              "      <td>0.052852</td>\n",
              "      <td>0.009204</td>\n",
              "      <td>0.024139</td>\n",
              "      <td>0.030022</td>\n",
              "      <td>0.050047</td>\n",
              "      <td>0.008761</td>\n",
              "      <td>0.059479</td>\n",
              "      <td>0.046724</td>\n",
              "      <td>0.076953</td>\n",
              "      <td>-0.102293</td>\n",
              "      <td>-0.032902</td>\n",
              "      <td>-0.251430</td>\n",
              "      <td>-0.005362</td>\n",
              "      <td>-0.009977</td>\n",
              "      <td>-0.703432</td>\n",
              "      <td>1.789861e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PHC_VSP</th>\n",
              "      <td>-0.106292</td>\n",
              "      <td>-0.333798</td>\n",
              "      <td>-0.194058</td>\n",
              "      <td>-0.076486</td>\n",
              "      <td>-0.180630</td>\n",
              "      <td>-0.027985</td>\n",
              "      <td>0.133198</td>\n",
              "      <td>-0.072184</td>\n",
              "      <td>0.161752</td>\n",
              "      <td>-0.406878</td>\n",
              "      <td>-0.201935</td>\n",
              "      <td>-0.152993</td>\n",
              "      <td>0.570051</td>\n",
              "      <td>-0.053277</td>\n",
              "      <td>0.438243</td>\n",
              "      <td>-0.037083</td>\n",
              "      <td>-0.006091</td>\n",
              "      <td>-0.015671</td>\n",
              "      <td>4.017960e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NXTENDON_2.0</th>\n",
              "      <td>-0.015843</td>\n",
              "      <td>-0.075640</td>\n",
              "      <td>0.060471</td>\n",
              "      <td>0.542902</td>\n",
              "      <td>0.181065</td>\n",
              "      <td>-0.178102</td>\n",
              "      <td>-0.142385</td>\n",
              "      <td>0.131901</td>\n",
              "      <td>-0.423965</td>\n",
              "      <td>-0.597310</td>\n",
              "      <td>0.142400</td>\n",
              "      <td>0.183475</td>\n",
              "      <td>-0.052208</td>\n",
              "      <td>0.011334</td>\n",
              "      <td>-0.010437</td>\n",
              "      <td>0.002352</td>\n",
              "      <td>0.001199</td>\n",
              "      <td>0.003926</td>\n",
              "      <td>-2.724196e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PTGENDER_2.0</th>\n",
              "      <td>0.014430</td>\n",
              "      <td>0.175560</td>\n",
              "      <td>-0.122540</td>\n",
              "      <td>-0.165007</td>\n",
              "      <td>-0.140734</td>\n",
              "      <td>-0.477621</td>\n",
              "      <td>0.226078</td>\n",
              "      <td>-0.482285</td>\n",
              "      <td>-0.428661</td>\n",
              "      <td>-0.052387</td>\n",
              "      <td>0.059847</td>\n",
              "      <td>-0.426965</td>\n",
              "      <td>-0.040126</td>\n",
              "      <td>-0.002752</td>\n",
              "      <td>-0.143826</td>\n",
              "      <td>-0.012669</td>\n",
              "      <td>0.011765</td>\n",
              "      <td>-0.010523</td>\n",
              "      <td>-6.898878e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AGE</th>\n",
              "      <td>-0.012347</td>\n",
              "      <td>-0.303235</td>\n",
              "      <td>0.084498</td>\n",
              "      <td>0.266868</td>\n",
              "      <td>-0.114263</td>\n",
              "      <td>0.127489</td>\n",
              "      <td>-0.220183</td>\n",
              "      <td>0.192907</td>\n",
              "      <td>0.097070</td>\n",
              "      <td>0.073674</td>\n",
              "      <td>0.200887</td>\n",
              "      <td>-0.766557</td>\n",
              "      <td>-0.237718</td>\n",
              "      <td>-0.089496</td>\n",
              "      <td>0.061248</td>\n",
              "      <td>-0.057357</td>\n",
              "      <td>0.001042</td>\n",
              "      <td>0.012539</td>\n",
              "      <td>2.438584e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NXVISUAL_1.0</th>\n",
              "      <td>-0.216030</td>\n",
              "      <td>0.051032</td>\n",
              "      <td>0.074408</td>\n",
              "      <td>0.015968</td>\n",
              "      <td>-0.171540</td>\n",
              "      <td>0.045072</td>\n",
              "      <td>0.056458</td>\n",
              "      <td>-0.439630</td>\n",
              "      <td>0.471294</td>\n",
              "      <td>-0.396430</td>\n",
              "      <td>0.042347</td>\n",
              "      <td>0.128312</td>\n",
              "      <td>-0.541447</td>\n",
              "      <td>-0.141939</td>\n",
              "      <td>0.071530</td>\n",
              "      <td>-0.029043</td>\n",
              "      <td>-0.014529</td>\n",
              "      <td>0.001120</td>\n",
              "      <td>-2.054190e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NXCONSCI_2.0</th>\n",
              "      <td>0.000579</td>\n",
              "      <td>-0.036475</td>\n",
              "      <td>0.045739</td>\n",
              "      <td>-0.007693</td>\n",
              "      <td>0.565915</td>\n",
              "      <td>-0.529420</td>\n",
              "      <td>0.366961</td>\n",
              "      <td>0.233575</td>\n",
              "      <td>0.410028</td>\n",
              "      <td>0.015164</td>\n",
              "      <td>0.159375</td>\n",
              "      <td>-0.091276</td>\n",
              "      <td>-0.021778</td>\n",
              "      <td>-0.022701</td>\n",
              "      <td>0.043722</td>\n",
              "      <td>-0.041094</td>\n",
              "      <td>-0.001306</td>\n",
              "      <td>-0.008877</td>\n",
              "      <td>-4.839103e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NXVISUAL_-4.0</th>\n",
              "      <td>0.489839</td>\n",
              "      <td>-0.088060</td>\n",
              "      <td>-0.109385</td>\n",
              "      <td>-0.068131</td>\n",
              "      <td>-0.008557</td>\n",
              "      <td>0.004186</td>\n",
              "      <td>-0.012954</td>\n",
              "      <td>-0.020681</td>\n",
              "      <td>0.016161</td>\n",
              "      <td>-0.063391</td>\n",
              "      <td>0.062016</td>\n",
              "      <td>0.046683</td>\n",
              "      <td>-0.051399</td>\n",
              "      <td>-0.246476</td>\n",
              "      <td>0.002263</td>\n",
              "      <td>0.022386</td>\n",
              "      <td>-0.400909</td>\n",
              "      <td>0.008837</td>\n",
              "      <td>7.071068e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PTHAND_-4.0</th>\n",
              "      <td>0.003803</td>\n",
              "      <td>0.026657</td>\n",
              "      <td>0.018997</td>\n",
              "      <td>0.035246</td>\n",
              "      <td>0.354352</td>\n",
              "      <td>0.641731</td>\n",
              "      <td>0.563920</td>\n",
              "      <td>-0.173767</td>\n",
              "      <td>-0.178019</td>\n",
              "      <td>-0.090063</td>\n",
              "      <td>0.229093</td>\n",
              "      <td>-0.132947</td>\n",
              "      <td>0.043765</td>\n",
              "      <td>-0.001051</td>\n",
              "      <td>0.007913</td>\n",
              "      <td>0.011906</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>-0.002324</td>\n",
              "      <td>1.635477e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NXTREMOR_1.0</th>\n",
              "      <td>-0.156652</td>\n",
              "      <td>0.150895</td>\n",
              "      <td>-0.029308</td>\n",
              "      <td>-0.379991</td>\n",
              "      <td>-0.101469</td>\n",
              "      <td>0.011182</td>\n",
              "      <td>-0.242333</td>\n",
              "      <td>0.102094</td>\n",
              "      <td>0.032761</td>\n",
              "      <td>-0.146782</td>\n",
              "      <td>0.810478</td>\n",
              "      <td>0.062388</td>\n",
              "      <td>0.207550</td>\n",
              "      <td>-0.009700</td>\n",
              "      <td>0.020105</td>\n",
              "      <td>-0.027413</td>\n",
              "      <td>-0.012099</td>\n",
              "      <td>-0.003458</td>\n",
              "      <td>-1.879874e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NXTENDON_-4.0</th>\n",
              "      <td>0.479970</td>\n",
              "      <td>-0.083560</td>\n",
              "      <td>-0.108382</td>\n",
              "      <td>-0.068434</td>\n",
              "      <td>-0.013084</td>\n",
              "      <td>0.011689</td>\n",
              "      <td>-0.017291</td>\n",
              "      <td>-0.021696</td>\n",
              "      <td>0.037335</td>\n",
              "      <td>-0.074730</td>\n",
              "      <td>0.072205</td>\n",
              "      <td>0.052736</td>\n",
              "      <td>-0.052793</td>\n",
              "      <td>-0.222810</td>\n",
              "      <td>0.012066</td>\n",
              "      <td>0.012802</td>\n",
              "      <td>0.822972</td>\n",
              "      <td>-0.011947</td>\n",
              "      <td>6.393951e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NXGAIT_-4.0</th>\n",
              "      <td>0.489839</td>\n",
              "      <td>-0.088060</td>\n",
              "      <td>-0.109385</td>\n",
              "      <td>-0.068131</td>\n",
              "      <td>-0.008557</td>\n",
              "      <td>0.004186</td>\n",
              "      <td>-0.012954</td>\n",
              "      <td>-0.020681</td>\n",
              "      <td>0.016161</td>\n",
              "      <td>-0.063391</td>\n",
              "      <td>0.062016</td>\n",
              "      <td>0.046683</td>\n",
              "      <td>-0.051399</td>\n",
              "      <td>-0.246476</td>\n",
              "      <td>0.002263</td>\n",
              "      <td>0.022386</td>\n",
              "      <td>-0.400909</td>\n",
              "      <td>0.008837</td>\n",
              "      <td>-7.071068e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NXOTHER_2.0</th>\n",
              "      <td>0.009484</td>\n",
              "      <td>-0.049945</td>\n",
              "      <td>0.086581</td>\n",
              "      <td>0.569188</td>\n",
              "      <td>-0.329919</td>\n",
              "      <td>-0.127599</td>\n",
              "      <td>0.241251</td>\n",
              "      <td>-0.227728</td>\n",
              "      <td>0.100147</td>\n",
              "      <td>0.410793</td>\n",
              "      <td>0.328790</td>\n",
              "      <td>0.218680</td>\n",
              "      <td>0.244520</td>\n",
              "      <td>-0.172659</td>\n",
              "      <td>0.078867</td>\n",
              "      <td>-0.014797</td>\n",
              "      <td>0.001637</td>\n",
              "      <td>-0.002683</td>\n",
              "      <td>-4.522868e-18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NXPLANTA_-4.0</th>\n",
              "      <td>0.361252</td>\n",
              "      <td>-0.057440</td>\n",
              "      <td>-0.115205</td>\n",
              "      <td>0.108962</td>\n",
              "      <td>-0.116654</td>\n",
              "      <td>0.003331</td>\n",
              "      <td>0.032825</td>\n",
              "      <td>-0.105954</td>\n",
              "      <td>0.196806</td>\n",
              "      <td>-0.076726</td>\n",
              "      <td>0.130534</td>\n",
              "      <td>-0.014241</td>\n",
              "      <td>-0.026681</td>\n",
              "      <td>0.865119</td>\n",
              "      <td>-0.017732</td>\n",
              "      <td>-0.057899</td>\n",
              "      <td>-0.019531</td>\n",
              "      <td>-0.008841</td>\n",
              "      <td>5.450078e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PTTLANG_2.0</th>\n",
              "      <td>0.002594</td>\n",
              "      <td>0.024655</td>\n",
              "      <td>0.092369</td>\n",
              "      <td>-0.125085</td>\n",
              "      <td>-0.530546</td>\n",
              "      <td>-0.041459</td>\n",
              "      <td>0.531360</td>\n",
              "      <td>0.566335</td>\n",
              "      <td>-0.120785</td>\n",
              "      <td>-0.134150</td>\n",
              "      <td>-0.002223</td>\n",
              "      <td>0.057742</td>\n",
              "      <td>-0.229107</td>\n",
              "      <td>0.016344</td>\n",
              "      <td>-0.011643</td>\n",
              "      <td>0.006437</td>\n",
              "      <td>0.000471</td>\n",
              "      <td>-0.008469</td>\n",
              "      <td>8.531791e-18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    PC1       PC2       PC3       PC4       PC5       PC6  \\\n",
              "PHC_MEM        0.001072  0.359827 -0.389360  0.080056  0.070478 -0.001679   \n",
              "PTCOGBEG       0.036229  0.484679 -0.211937  0.207516 -0.051583  0.039036   \n",
              "PTADDX         0.073074  0.482489 -0.132886  0.189855 -0.064794  0.092312   \n",
              "PHC_LAN       -0.187430 -0.237548 -0.566755  0.035224  0.004257  0.006745   \n",
              "PHC_EXF       -0.185009 -0.223970 -0.572115  0.052852  0.009204  0.024139   \n",
              "PHC_VSP       -0.106292 -0.333798 -0.194058 -0.076486 -0.180630 -0.027985   \n",
              "NXTENDON_2.0  -0.015843 -0.075640  0.060471  0.542902  0.181065 -0.178102   \n",
              "PTGENDER_2.0   0.014430  0.175560 -0.122540 -0.165007 -0.140734 -0.477621   \n",
              "AGE           -0.012347 -0.303235  0.084498  0.266868 -0.114263  0.127489   \n",
              "NXVISUAL_1.0  -0.216030  0.051032  0.074408  0.015968 -0.171540  0.045072   \n",
              "NXCONSCI_2.0   0.000579 -0.036475  0.045739 -0.007693  0.565915 -0.529420   \n",
              "NXVISUAL_-4.0  0.489839 -0.088060 -0.109385 -0.068131 -0.008557  0.004186   \n",
              "PTHAND_-4.0    0.003803  0.026657  0.018997  0.035246  0.354352  0.641731   \n",
              "NXTREMOR_1.0  -0.156652  0.150895 -0.029308 -0.379991 -0.101469  0.011182   \n",
              "NXTENDON_-4.0  0.479970 -0.083560 -0.108382 -0.068434 -0.013084  0.011689   \n",
              "NXGAIT_-4.0    0.489839 -0.088060 -0.109385 -0.068131 -0.008557  0.004186   \n",
              "NXOTHER_2.0    0.009484 -0.049945  0.086581  0.569188 -0.329919 -0.127599   \n",
              "NXPLANTA_-4.0  0.361252 -0.057440 -0.115205  0.108962 -0.116654  0.003331   \n",
              "PTTLANG_2.0    0.002594  0.024655  0.092369 -0.125085 -0.530546 -0.041459   \n",
              "\n",
              "                    PC7       PC8       PC9      PC10      PC11      PC12  \\\n",
              "PHC_MEM       -0.038301  0.082303 -0.156810  0.169082  0.021889  0.018530   \n",
              "PTCOGBEG      -0.014900  0.104569  0.207922 -0.118194 -0.039418 -0.187855   \n",
              "PTADDX        -0.006305  0.109903  0.211397 -0.165021 -0.116566 -0.140856   \n",
              "PHC_LAN        0.054099  0.041101  0.007637  0.053582  0.050989  0.082257   \n",
              "PHC_EXF        0.030022  0.050047  0.008761  0.059479  0.046724  0.076953   \n",
              "PHC_VSP        0.133198 -0.072184  0.161752 -0.406878 -0.201935 -0.152993   \n",
              "NXTENDON_2.0  -0.142385  0.131901 -0.423965 -0.597310  0.142400  0.183475   \n",
              "PTGENDER_2.0   0.226078 -0.482285 -0.428661 -0.052387  0.059847 -0.426965   \n",
              "AGE           -0.220183  0.192907  0.097070  0.073674  0.200887 -0.766557   \n",
              "NXVISUAL_1.0   0.056458 -0.439630  0.471294 -0.396430  0.042347  0.128312   \n",
              "NXCONSCI_2.0   0.366961  0.233575  0.410028  0.015164  0.159375 -0.091276   \n",
              "NXVISUAL_-4.0 -0.012954 -0.020681  0.016161 -0.063391  0.062016  0.046683   \n",
              "PTHAND_-4.0    0.563920 -0.173767 -0.178019 -0.090063  0.229093 -0.132947   \n",
              "NXTREMOR_1.0  -0.242333  0.102094  0.032761 -0.146782  0.810478  0.062388   \n",
              "NXTENDON_-4.0 -0.017291 -0.021696  0.037335 -0.074730  0.072205  0.052736   \n",
              "NXGAIT_-4.0   -0.012954 -0.020681  0.016161 -0.063391  0.062016  0.046683   \n",
              "NXOTHER_2.0    0.241251 -0.227728  0.100147  0.410793  0.328790  0.218680   \n",
              "NXPLANTA_-4.0  0.032825 -0.105954  0.196806 -0.076726  0.130534 -0.014241   \n",
              "PTTLANG_2.0    0.531360  0.566335 -0.120785 -0.134150 -0.002223  0.057742   \n",
              "\n",
              "                   PC13      PC14      PC15      PC16      PC17      PC18  \\\n",
              "PHC_MEM       -0.263598  0.023218  0.729877 -0.206129 -0.004861  0.006753   \n",
              "PTCOGBEG       0.123804 -0.033639 -0.049528  0.739919  0.001828 -0.003383   \n",
              "PTADDX         0.226397 -0.124883 -0.337585 -0.629758 -0.004443  0.023345   \n",
              "PHC_LAN       -0.089286 -0.015991 -0.238164  0.019281  0.013884  0.709577   \n",
              "PHC_EXF       -0.102293 -0.032902 -0.251430 -0.005362 -0.009977 -0.703432   \n",
              "PHC_VSP        0.570051 -0.053277  0.438243 -0.037083 -0.006091 -0.015671   \n",
              "NXTENDON_2.0  -0.052208  0.011334 -0.010437  0.002352  0.001199  0.003926   \n",
              "PTGENDER_2.0  -0.040126 -0.002752 -0.143826 -0.012669  0.011765 -0.010523   \n",
              "AGE           -0.237718 -0.089496  0.061248 -0.057357  0.001042  0.012539   \n",
              "NXVISUAL_1.0  -0.541447 -0.141939  0.071530 -0.029043 -0.014529  0.001120   \n",
              "NXCONSCI_2.0  -0.021778 -0.022701  0.043722 -0.041094 -0.001306 -0.008877   \n",
              "NXVISUAL_-4.0 -0.051399 -0.246476  0.002263  0.022386 -0.400909  0.008837   \n",
              "PTHAND_-4.0    0.043765 -0.001051  0.007913  0.011906  0.000213 -0.002324   \n",
              "NXTREMOR_1.0   0.207550 -0.009700  0.020105 -0.027413 -0.012099 -0.003458   \n",
              "NXTENDON_-4.0 -0.052793 -0.222810  0.012066  0.012802  0.822972 -0.011947   \n",
              "NXGAIT_-4.0   -0.051399 -0.246476  0.002263  0.022386 -0.400909  0.008837   \n",
              "NXOTHER_2.0    0.244520 -0.172659  0.078867 -0.014797  0.001637 -0.002683   \n",
              "NXPLANTA_-4.0 -0.026681  0.865119 -0.017732 -0.057899 -0.019531 -0.008841   \n",
              "PTTLANG_2.0   -0.229107  0.016344 -0.011643  0.006437  0.000471 -0.008469   \n",
              "\n",
              "                       PC19  \n",
              "PHC_MEM        5.091890e-18  \n",
              "PTCOGBEG       3.791831e-18  \n",
              "PTADDX         5.789338e-17  \n",
              "PHC_LAN       -2.635904e-16  \n",
              "PHC_EXF        1.789861e-16  \n",
              "PHC_VSP        4.017960e-17  \n",
              "NXTENDON_2.0  -2.724196e-16  \n",
              "PTGENDER_2.0  -6.898878e-17  \n",
              "AGE            2.438584e-17  \n",
              "NXVISUAL_1.0  -2.054190e-16  \n",
              "NXCONSCI_2.0  -4.839103e-17  \n",
              "NXVISUAL_-4.0  7.071068e-01  \n",
              "PTHAND_-4.0    1.635477e-16  \n",
              "NXTREMOR_1.0  -1.879874e-16  \n",
              "NXTENDON_-4.0  6.393951e-17  \n",
              "NXGAIT_-4.0   -7.071068e-01  \n",
              "NXOTHER_2.0   -4.522868e-18  \n",
              "NXPLANTA_-4.0  5.450078e-17  \n",
              "PTTLANG_2.0    8.531791e-18  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loadings = pd.DataFrame(\n",
        "    pca.components_.T,\n",
        "    columns=component_names,\n",
        "    index=X_scaled.columns,\n",
        ")\n",
        "loadings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "2ejOGDxRjdZE",
        "outputId": "af8f27d4-2437-4ad5-dedb-41c594172e24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([<Axes: title={'center': '% Explained Variance'}, xlabel='Component'>,\n",
              "       <Axes: title={'center': '% Cumulative Variance'}, xlabel='Component'>],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_variance(pca, width=8, dpi=100):\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2)\n",
        "    n = pca.n_components_\n",
        "    grid = np.arange(1, n + 1)\n",
        "\n",
        "    evr = pca.explained_variance_ratio_\n",
        "    axs[0].bar(grid, evr)\n",
        "    axs[0].set(\n",
        "        xlabel=\"Component\", title=\"% Explained Variance\", ylim=(0.0, 1.0)\n",
        "    )\n",
        "    cv = np.cumsum(evr)\n",
        "    axs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\")\n",
        "    axs[1].set(\n",
        "        xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0)\n",
        "    )\n",
        "    fig.set(figwidth=8, dpi=100)\n",
        "    return axs\n",
        "\n",
        "plot_variance(pca)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjnjB49Wj1t2",
        "outputId": "953b3a38-6474-46a8-b385-3a7530d3163a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PC3     0.342918\n",
              "PC2     0.225809\n",
              "PC16    0.178584\n",
              "PC1     0.087392\n",
              "PC4     0.083147\n",
              "PC15    0.068412\n",
              "PC8     0.061617\n",
              "PC17    0.052474\n",
              "PC6     0.050752\n",
              "PC9     0.046804\n",
              "PC10    0.045558\n",
              "PC5     0.034402\n",
              "PC18    0.034258\n",
              "PC14    0.032541\n",
              "PC13    0.030431\n",
              "PC12    0.024500\n",
              "PC7     0.001509\n",
              "PC11    0.000000\n",
              "PC19    0.000000\n",
              "Name: MI Scores, dtype: float64"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mi_scores = make_mi_scores(X_pca, y)\n",
        "mi_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORKwUPsKtqfd"
      },
      "source": [
        "# **Ignore**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "BcEoiFMmmu7E"
      },
      "outputs": [],
      "source": [
        "sampling_strategy = {0: 400 , 1: 600, 2:276  }\n",
        "rus = RandomUnderSampler(random_state=42, sampling_strategy=sampling_strategy)\n",
        "X, y = rus.fit_resample(X,y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYezA8jhzIbd"
      },
      "source": [
        "# **Continue**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "z49nJIpktSr4"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0FoKzyfFuMbV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000727 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1125\n",
            "[LightGBM] [Info] Number of data points in the train set: 2008, number of used features: 14\n",
            "[LightGBM] [Info] Start training from score -0.884674\n",
            "[LightGBM] [Info] Start training from score -1.065309\n",
            "[LightGBM] [Info] Start training from score -1.416630\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.01, max_depth=3, n_estimators=200,\n",
              "               random_state=51, reg_alpha=0.05, subsample=0.6,\n",
              "               subsample_for_bin=3500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(learning_rate=0.01, max_depth=3, n_estimators=200,\n",
              "               random_state=51, reg_alpha=0.05, subsample=0.6,\n",
              "               subsample_for_bin=3500)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "LGBMClassifier(learning_rate=0.01, max_depth=3, n_estimators=200,\n",
              "               random_state=51, reg_alpha=0.05, subsample=0.6,\n",
              "               subsample_for_bin=3500)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lgb_params = {\n",
        "    'boosting_type':'gbdt',\n",
        "    'num_leaves':31,\n",
        "    'max_depth':3,\n",
        "    'learning_rate':0.01,\n",
        "    'n_estimators':200,\n",
        "    'subsample_for_bin':3500, #can decrease this\n",
        "    'min_child_weight':0.001,\n",
        "    'min_child_samples':20,\n",
        "    'subsample':0.6,\n",
        "    'reg_alpha':0.05,\n",
        "    'random_state':51\n",
        "             }\n",
        "\n",
        "\n",
        "m = lgb.LGBMClassifier(**lgb_params)\n",
        "m.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kil3vJ7Ju39j"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1., 0., 2., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
              "       2., 2., 1., 2., 1., 2., 2., 2., 1., 1., 1., 2., 0., 0., 1., 0., 2.,\n",
              "       1., 1., 1., 2., 0., 0., 1., 0., 0., 0., 0., 0., 2., 2., 0., 0., 1.,\n",
              "       1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
              "       0., 2., 0., 0., 1., 1., 0., 1., 0., 1., 2., 0., 0., 2., 1., 0., 2.,\n",
              "       2., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 2., 0., 1., 2., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
              "       1., 0., 2., 0., 1., 2., 0., 0., 1., 0., 0., 2., 1., 0., 0., 1., 1.,\n",
              "       1., 1., 1., 0., 1., 0., 1., 0., 0., 2., 2., 0., 2., 1., 0., 2., 0.,\n",
              "       1., 2., 2., 1., 0., 2., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
              "       2., 2., 0., 1., 1., 0., 0., 1., 2., 0., 0., 1., 0., 2., 1., 1., 0.,\n",
              "       2., 2., 1., 0., 0., 0., 1., 1., 1., 2., 0., 0., 0., 1., 2., 0., 0.,\n",
              "       0., 0., 2., 0., 0., 1., 1., 2., 0., 0., 1., 0., 0., 0., 0., 2., 2.,\n",
              "       1., 1., 0.])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = m.predict(X_test)\n",
        "y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Bd2r3KbxuzX",
        "outputId": "82e4ee10-c834-4133-d553-296d69fd446f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.93      0.92       100\n",
            "         1.0       0.86      0.83      0.85        83\n",
            "         2.0       0.90      0.90      0.90        41\n",
            "\n",
            "    accuracy                           0.89       224\n",
            "   macro avg       0.89      0.89      0.89       224\n",
            "weighted avg       0.89      0.89      0.89       224\n",
            "\n"
          ]
        }
      ],
      "source": [
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<lightgbm.basic.Booster at 0x1ad1cab7e50>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "m.booster_.save_model('lgbm_model.txt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3is2LEhkmnzT"
      },
      "source": [
        "# **Deep Learning Approach**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "9z3uEMNDVI5M"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXVbOaXQVSCG",
        "outputId": "d2f74afe-13f7-4357-dac5-3cbdeb70b441"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['PTID', 'Phase', 'VISDATE', 'PTDOB']"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "obj_cols = [col for col in clinical.columns if clinical[col].dtype == 'object']\n",
        "obj_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTV_j8JFVTAn"
      },
      "outputs": [],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEzGbxCIXo7b",
        "outputId": "45b5fb67-f172-439e-bdf6-6622be9826f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Adya2\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,848</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m14,848\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,179</span> (102.26 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,179\u001b[0m (102.26 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,731</span> (100.51 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,731\u001b[0m (100.51 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape = (115,), activation = \"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation = \"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(32, activation = \"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(3, activation = \"softmax\"))\n",
        "\n",
        "model.compile(Adam(learning_rate = 0.0001), \"sparse_categorical_crossentropy\", metrics = [\"sparse_categorical_accuracy\"])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2FmlztsZCw8",
        "outputId": "71ee682b-30c3-4800-b132-bc535e088bd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 1.7119 - sparse_categorical_accuracy: 0.3500 - val_loss: 1.0183 - val_sparse_categorical_accuracy: 0.5698\n",
            "Epoch 2/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3242 - sparse_categorical_accuracy: 0.4989 - val_loss: 0.7403 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 3/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1405 - sparse_categorical_accuracy: 0.5767 - val_loss: 0.6828 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 4/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.1466 - sparse_categorical_accuracy: 0.5941 - val_loss: 0.6621 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 5/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0781 - sparse_categorical_accuracy: 0.6149 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 6/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0036 - sparse_categorical_accuracy: 0.6126 - val_loss: 0.6620 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 7/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9531 - sparse_categorical_accuracy: 0.6346 - val_loss: 0.6555 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 8/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9850 - sparse_categorical_accuracy: 0.6206 - val_loss: 0.6548 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 9/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9942 - sparse_categorical_accuracy: 0.6213 - val_loss: 0.6575 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 10/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9066 - sparse_categorical_accuracy: 0.6552 - val_loss: 0.6534 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 11/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9123 - sparse_categorical_accuracy: 0.6616 - val_loss: 0.6558 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 12/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9553 - sparse_categorical_accuracy: 0.6249 - val_loss: 0.6522 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 13/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9421 - sparse_categorical_accuracy: 0.6460 - val_loss: 0.6473 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 14/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9214 - sparse_categorical_accuracy: 0.6410 - val_loss: 0.6432 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 15/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9450 - sparse_categorical_accuracy: 0.6360 - val_loss: 0.6410 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 16/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.9099 - sparse_categorical_accuracy: 0.6509 - val_loss: 0.6382 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 17/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8913 - sparse_categorical_accuracy: 0.6397 - val_loss: 0.6370 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 18/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8391 - sparse_categorical_accuracy: 0.6740 - val_loss: 0.6344 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 19/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8767 - sparse_categorical_accuracy: 0.6600 - val_loss: 0.6307 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 20/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8501 - sparse_categorical_accuracy: 0.6645 - val_loss: 0.6241 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 21/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8448 - sparse_categorical_accuracy: 0.6561 - val_loss: 0.6242 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 22/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.8536 - sparse_categorical_accuracy: 0.6610 - val_loss: 0.6274 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 23/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8281 - sparse_categorical_accuracy: 0.6644 - val_loss: 0.6266 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 24/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8477 - sparse_categorical_accuracy: 0.6569 - val_loss: 0.6244 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 25/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7629 - sparse_categorical_accuracy: 0.6920 - val_loss: 0.6229 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 26/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8398 - sparse_categorical_accuracy: 0.6568 - val_loss: 0.6223 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 27/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8933 - sparse_categorical_accuracy: 0.6383 - val_loss: 0.6214 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 28/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8297 - sparse_categorical_accuracy: 0.6597 - val_loss: 0.6212 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 29/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.8279 - sparse_categorical_accuracy: 0.6580 - val_loss: 0.6193 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 30/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8160 - sparse_categorical_accuracy: 0.6656 - val_loss: 0.6129 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 31/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8182 - sparse_categorical_accuracy: 0.6697 - val_loss: 0.6114 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 32/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8703 - sparse_categorical_accuracy: 0.6469 - val_loss: 0.6084 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 33/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8200 - sparse_categorical_accuracy: 0.6796 - val_loss: 0.6090 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 34/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8158 - sparse_categorical_accuracy: 0.6834 - val_loss: 0.6068 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 35/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8138 - sparse_categorical_accuracy: 0.6693 - val_loss: 0.6056 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 36/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8053 - sparse_categorical_accuracy: 0.6605 - val_loss: 0.6047 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 37/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7661 - sparse_categorical_accuracy: 0.6830 - val_loss: 0.6063 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 38/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8170 - sparse_categorical_accuracy: 0.6645 - val_loss: 0.6057 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 39/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8208 - sparse_categorical_accuracy: 0.6603 - val_loss: 0.6050 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 40/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8124 - sparse_categorical_accuracy: 0.6649 - val_loss: 0.6063 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 41/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7618 - sparse_categorical_accuracy: 0.6922 - val_loss: 0.6081 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 42/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7601 - sparse_categorical_accuracy: 0.6776 - val_loss: 0.6063 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 43/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.8130 - sparse_categorical_accuracy: 0.6703 - val_loss: 0.6056 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 44/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7560 - sparse_categorical_accuracy: 0.6792 - val_loss: 0.6031 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 45/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7467 - sparse_categorical_accuracy: 0.6892 - val_loss: 0.6049 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 46/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7767 - sparse_categorical_accuracy: 0.6622 - val_loss: 0.6058 - val_sparse_categorical_accuracy: 0.7765\n",
            "Epoch 47/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7912 - sparse_categorical_accuracy: 0.6748 - val_loss: 0.6036 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 48/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7622 - sparse_categorical_accuracy: 0.6695 - val_loss: 0.6046 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 49/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7856 - sparse_categorical_accuracy: 0.6717 - val_loss: 0.6040 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 50/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7950 - sparse_categorical_accuracy: 0.6750 - val_loss: 0.6039 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 51/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7772 - sparse_categorical_accuracy: 0.6779 - val_loss: 0.6036 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 52/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7606 - sparse_categorical_accuracy: 0.6833 - val_loss: 0.6042 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 53/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6997 - sparse_categorical_accuracy: 0.7003 - val_loss: 0.6016 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 54/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7776 - sparse_categorical_accuracy: 0.6755 - val_loss: 0.6017 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 55/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7860 - sparse_categorical_accuracy: 0.6735 - val_loss: 0.6048 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 56/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7513 - sparse_categorical_accuracy: 0.6751 - val_loss: 0.6038 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 57/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7484 - sparse_categorical_accuracy: 0.6721 - val_loss: 0.6030 - val_sparse_categorical_accuracy: 0.7821\n",
            "Epoch 58/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7441 - sparse_categorical_accuracy: 0.6869 - val_loss: 0.6056 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 59/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7334 - sparse_categorical_accuracy: 0.6853 - val_loss: 0.6028 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 60/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7067 - sparse_categorical_accuracy: 0.7052 - val_loss: 0.6011 - val_sparse_categorical_accuracy: 0.7709\n",
            "Epoch 61/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7978 - sparse_categorical_accuracy: 0.6631 - val_loss: 0.6011 - val_sparse_categorical_accuracy: 0.7709\n",
            "Epoch 62/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7594 - sparse_categorical_accuracy: 0.6779 - val_loss: 0.6000 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 63/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7580 - sparse_categorical_accuracy: 0.6690 - val_loss: 0.6002 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 64/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.7632 - sparse_categorical_accuracy: 0.6804 - val_loss: 0.6012 - val_sparse_categorical_accuracy: 0.7877\n",
            "Epoch 65/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7712 - sparse_categorical_accuracy: 0.6681 - val_loss: 0.5999 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 66/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7433 - sparse_categorical_accuracy: 0.6894 - val_loss: 0.5994 - val_sparse_categorical_accuracy: 0.7709\n",
            "Epoch 67/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7354 - sparse_categorical_accuracy: 0.6779 - val_loss: 0.6003 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 68/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6983 - sparse_categorical_accuracy: 0.7095 - val_loss: 0.5985 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 69/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7373 - sparse_categorical_accuracy: 0.6765 - val_loss: 0.5987 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 70/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7199 - sparse_categorical_accuracy: 0.7003 - val_loss: 0.5987 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 71/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7739 - sparse_categorical_accuracy: 0.6796 - val_loss: 0.5973 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 72/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7420 - sparse_categorical_accuracy: 0.6843 - val_loss: 0.5906 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 73/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7451 - sparse_categorical_accuracy: 0.6672 - val_loss: 0.5928 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 74/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7420 - sparse_categorical_accuracy: 0.6833 - val_loss: 0.5935 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 75/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7531 - sparse_categorical_accuracy: 0.6597 - val_loss: 0.5946 - val_sparse_categorical_accuracy: 0.7709\n",
            "Epoch 76/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7140 - sparse_categorical_accuracy: 0.7078 - val_loss: 0.5957 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 77/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7351 - sparse_categorical_accuracy: 0.6751 - val_loss: 0.5963 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 78/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7401 - sparse_categorical_accuracy: 0.6689 - val_loss: 0.5980 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 79/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7090 - sparse_categorical_accuracy: 0.7116 - val_loss: 0.5957 - val_sparse_categorical_accuracy: 0.7765\n",
            "Epoch 80/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7568 - sparse_categorical_accuracy: 0.6667 - val_loss: 0.5975 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 81/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7817 - sparse_categorical_accuracy: 0.6611 - val_loss: 0.5951 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 82/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7120 - sparse_categorical_accuracy: 0.6911 - val_loss: 0.5940 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 83/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7737 - sparse_categorical_accuracy: 0.6778 - val_loss: 0.5952 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 84/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7620 - sparse_categorical_accuracy: 0.6495 - val_loss: 0.5937 - val_sparse_categorical_accuracy: 0.7486\n",
            "Epoch 85/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7320 - sparse_categorical_accuracy: 0.6794 - val_loss: 0.5940 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 86/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6860 - sparse_categorical_accuracy: 0.7138 - val_loss: 0.5927 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 87/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7723 - sparse_categorical_accuracy: 0.6601 - val_loss: 0.5933 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 88/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7367 - sparse_categorical_accuracy: 0.6826 - val_loss: 0.5928 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 89/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6842 - sparse_categorical_accuracy: 0.6937 - val_loss: 0.5945 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 90/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7358 - sparse_categorical_accuracy: 0.6977 - val_loss: 0.5966 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 91/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6975 - sparse_categorical_accuracy: 0.7055 - val_loss: 0.5981 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 92/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7576 - sparse_categorical_accuracy: 0.6658 - val_loss: 0.5945 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 93/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.7200 - sparse_categorical_accuracy: 0.6768 - val_loss: 0.5943 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 94/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7484 - sparse_categorical_accuracy: 0.6696 - val_loss: 0.5932 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 95/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7405 - sparse_categorical_accuracy: 0.6961 - val_loss: 0.5927 - val_sparse_categorical_accuracy: 0.7709\n",
            "Epoch 96/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7258 - sparse_categorical_accuracy: 0.6986 - val_loss: 0.5956 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 97/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6792 - sparse_categorical_accuracy: 0.7015 - val_loss: 0.5951 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 98/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7164 - sparse_categorical_accuracy: 0.7145 - val_loss: 0.5960 - val_sparse_categorical_accuracy: 0.7654\n",
            "Epoch 99/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7264 - sparse_categorical_accuracy: 0.6810 - val_loss: 0.5941 - val_sparse_categorical_accuracy: 0.7598\n",
            "Epoch 100/100\n",
            "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6939 - sparse_categorical_accuracy: 0.7165 - val_loss: 0.5934 - val_sparse_categorical_accuracy: 0.7598\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train, y_train,  epochs=100, validation_split=0.1, batch_size=32,verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "bZapB2_mZPSx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.12872367, 0.70439523, 0.16688111],\n",
              "       [0.35153663, 0.2744154 , 0.37404794],\n",
              "       [0.01495771, 0.03957061, 0.9454716 ],\n",
              "       ...,\n",
              "       [0.9682082 , 0.02708461, 0.00470721],\n",
              "       [0.96810114, 0.0271911 , 0.00470779],\n",
              "       [0.9682303 , 0.02708147, 0.00468826]], dtype=float32)"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = np.argmax(y_pred, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.91      0.77      0.83       189\n",
            "         1.0       0.80      0.67      0.73       168\n",
            "         2.0       0.51      0.81      0.62        90\n",
            "\n",
            "    accuracy                           0.74       447\n",
            "   macro avg       0.74      0.75      0.73       447\n",
            "weighted avg       0.78      0.74      0.75       447\n",
            "\n"
          ]
        }
      ],
      "source": [
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Classification Report:\\n\", report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'Sequential' object has no attribute 'save_model'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[99], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDL_CLINICAL.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'save_model'"
          ]
        }
      ],
      "source": [
        "model.save_model(\"DL_CLINICAL.h5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
