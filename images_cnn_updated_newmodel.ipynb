{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "6f2babe2",
      "metadata": {
        "id": "6f2babe2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import VGG16\n",
        "from keras.applications import ResNet50\n",
        "from keras.applications import InceptionV3\n",
        "from keras.layers import Dense, Flatten, Dropout,Input,BatchNormalization\n",
        "from keras.models import Model,load_model\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout,Conv1D,MaxPooling1D\n",
        "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras import regularizers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-TygL9mgP2SE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TygL9mgP2SE",
        "outputId": "f92247ec-563f-4e63-c03a-6f57c3f8ec11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xtBLTYITV48v",
      "metadata": {
        "id": "xtBLTYITV48v"
      },
      "outputs": [],
      "source": [
        "!cd drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b2d2c4aa",
      "metadata": {
        "id": "b2d2c4aa"
      },
      "outputs": [],
      "source": [
        "dataset_dir = \"alzheimer_new_1/alzheimer_new/ADNI_DATASET\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "10c6fc24",
      "metadata": {
        "id": "10c6fc24"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "input_shape = (224, 224, 3)\n",
        "num_classes = 3\n",
        "batch_size = 32\n",
        "epochs = 200\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "93049f30",
      "metadata": {
        "id": "93049f30"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    \n",
        "    #shear_range=0.2,\n",
        "    \n",
        "    validation_split=0.3\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "7b85e457",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b85e457",
        "outputId": "ee87420a-7823-4f3b-f9f0-add4e5ed6046"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3608 images belonging to 3 classes.\n",
            "Found 1546 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "# Define train and validation generators\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(input_shape[0], input_shape[1]),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(input_shape[0], input_shape[1]),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "e637b45d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3608, 3)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_generator.classes\n",
        "y_train=keras.utils.to_categorical(train_generator.classes)\n",
        "y_train.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "0ead3fdf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ead3fdf",
        "outputId": "f34e0b97-12b6-4ec4-9a75-8128d6de5a03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training classes: 3\n",
            "Number of validation classes: 3\n"
          ]
        }
      ],
      "source": [
        "num_train_classes = train_generator.num_classes\n",
        "\n",
        "# Number of validation classes\n",
        "num_validation_classes = validation_generator.num_classes\n",
        "\n",
        "print(\"Number of training classes:\", num_train_classes)\n",
        "print(\"Number of validation classes:\", num_validation_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "0029ef21",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0029ef21",
        "outputId": "d63710d0-3851-4cda-ae5c-1cfc6b45491c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of images in each class in the training set:\n",
            "{'AD': 900, 'CN': 1152, 'MCI': 2072}\n",
            "\n",
            "Number of images in each class in the validation set:\n",
            "{'AD': 224, 'CN': 288, 'MCI': 518}\n"
          ]
        }
      ],
      "source": [
        "# Get the mapping of class indices to class names\n",
        "class_indices = train_generator.class_indices\n",
        "\n",
        "# Invert the mapping to get class names to class indices\n",
        "class_names = {v: k for k, v in class_indices.items()}\n",
        "\n",
        "# Initialize dictionaries to store the counts\n",
        "train_class_counts = {class_name: 0 for class_name in class_names.values()}\n",
        "validation_class_counts = {class_name: 0 for class_name in class_names.values()}\n",
        "\n",
        "# Count the number of images in each class for the training set\n",
        "for filename in train_generator.filenames:\n",
        "    class_name = os.path.dirname(filename)\n",
        "    train_class_counts[class_name] += 1\n",
        "\n",
        "# Count the number of images in each class for the validation set\n",
        "for filename in validation_generator.filenames:\n",
        "    class_name = os.path.dirname(filename)\n",
        "    validation_class_counts[class_name] += 1\n",
        "\n",
        "print(\"Number of images in each class in the training set:\")\n",
        "print(train_class_counts)\n",
        "\n",
        "print(\"\\nNumber of images in each class in the validation set:\")\n",
        "print(validation_class_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "81cdc40d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81cdc40d",
        "outputId": "866c4694-e480-4b32-d124-a3262096f550"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained VGG16 model\n",
        "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# Load pre-trained ResNet50 model\n",
        "# resnet_base = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# Load pre-trained inception model\n",
        "# inception_base = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "b9b9debc",
      "metadata": {
        "id": "b9b9debc"
      },
      "outputs": [],
      "source": [
        "# Freeze convolutional layers\n",
        "for layer in vgg_base.layers:\n",
        "     layer.trainable = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "s221kpMwSm_J",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s221kpMwSm_J",
        "outputId": "e373c861-73aa-4478-d92f-25a7ae83c940"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"vgg16\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"vgg16\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block2_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block3_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block3_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block4_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block4_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block4_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block4_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block5_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block5_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block5_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block5_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block1_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block1_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block1_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block2_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block2_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block2_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block3_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block3_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block3_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block3_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block4_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block4_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block4_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block4_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block5_conv1 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block5_conv2 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block5_conv3 (\u001b[38;5;33mConv2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)    │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block5_pool (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,714,688\u001b[0m (56.13 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "vgg_base.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4pLXz6xS3TF",
      "metadata": {
        "id": "d4pLXz6xS3TF"
      },
      "source": [
        "Output_VGG_Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "id": "q8XJKoe-S2HL",
      "metadata": {
        "id": "q8XJKoe-S2HL"
      },
      "outputs": [],
      "source": [
        "output_vgg_layer=vgg_base.get_layer(\"block5_pool\")\n",
        "output_vgg=output_vgg_layer.output\n",
        "features_vgg=Flatten()(output_vgg)\n",
        "model=Model(inputs=vgg_base.input,outputs=features_vgg)\n",
        "#plot_model(model, show_shapes = True, show_layer_names = True, to_file = 'feature_extract.png')\n",
        "#model.compile(optimizer=Adam)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "fbd0c02a",
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "File format not supported: filepath=best_model (1).h. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(best_model (1).h, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name).",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_model (1).h\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\saving\\saving_api.py:191\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    186\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlegacy H5 format files (`.h5` extension). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that the legacy SavedModel format is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    196\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported by `load_model()` in Keras 3. In \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morder to reload a TensorFlow SavedModel as an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minference-only layer in Keras 3, use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`keras.layers.TFSMLayer(\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, call_endpoint=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserving_default\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(note that your `call_endpoint` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmight have a different name).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m     )\n",
            "\u001b[1;31mValueError\u001b[0m: File format not supported: filepath=best_model (1).h. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(best_model (1).h, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name)."
          ]
        }
      ],
      "source": [
        "#model=load_model('best_model (1).h')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YGyEEdXYuARp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGyEEdXYuARp",
        "outputId": "e7c437d5-34d2-4296-df8b-566f37b804ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "id": "ACSZJLOJXQPo",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACSZJLOJXQPo",
        "outputId": "6359d1d3-3cde-4e17-e9de-2151909b5c00"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Adya2\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:120: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m623s\u001b[0m 5s/step\n"
          ]
        }
      ],
      "source": [
        "train_features=model.predict(train_generator)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "id": "37b66105",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 4s/step\n"
          ]
        }
      ],
      "source": [
        "validation_features = model.predict(validation_generator)\n",
        "\n",
        "# Evaluate the model using PCA-transformed validation features and labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "id": "bb941d64",
      "metadata": {},
      "outputs": [],
      "source": [
        "np.save(\"test_features_noaugment.npy\",validation_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "id": "_rjqMNzgXhP9",
      "metadata": {
        "id": "_rjqMNzgXhP9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.save(\"train_features_noaugment.npy\",train_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "id": "20af1a5c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4124, 25088)"
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_features.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8sI76BRMY0o6",
      "metadata": {
        "id": "8sI76BRMY0o6"
      },
      "source": [
        "# **PCA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "id": "5oHfObJ6Y51l",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 907
        },
        "id": "5oHfObJ6Y51l",
        "outputId": "eca6c8f9-d181-41ee-d440-37c95d3b4f44"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "train_features=np.load(\"train_features_noaugment.npy\")\n",
        "scaler = StandardScaler()\n",
        "X_sc_train = scaler.fit_transform(train_features)\n",
        "\n",
        "pca = PCA()#add n_components=the feature at 95%\n",
        "pca.fit(X_sc_train)\n",
        "features_pca_train = pca.fit_transform(X_sc_train)\n",
        "\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('Number of components')\n",
        "plt.ylabel('Cumulative explained variance')\n",
        "\n",
        "\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "xi = np.arange(1, 4125, step = 1)\n",
        "y = np.cumsum(pca.explained_variance_ratio_)\n",
        "\n",
        "plt.ylim(0.0,1.1)\n",
        "plt.plot(xi, y, marker='o', linestyle='--', color='b')\n",
        "\n",
        "plt.xlabel('Number of Components')\n",
        "plt.xticks(np.arange(0, 15000, step = 1000)) #change from 0-based array index to 1-based human-readable label\n",
        "plt.ylabel('Cumulative variance (%)')\n",
        "plt.title('The number of components needed to explain variance')\n",
        "\n",
        "plt.axhline(y=0.95, color='r', linestyle='-')\n",
        "plt.text(0.5, 0.85, '95% cut-off threshold', color = 'red', fontsize=16)\n",
        "ax.grid(axis='x')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "id": "0B3b9W4QJ0nK",
      "metadata": {
        "id": "0B3b9W4QJ0nK"
      },
      "outputs": [],
      "source": [
        "n_components = 1200\n",
        "pca=PCA(n_components)\n",
        "features_pca_train = pca.fit_transform(X_sc_train)\n",
        "np.save('features_pca_train_normalized.npy', features_pca_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "5537860f",
      "metadata": {},
      "outputs": [],
      "source": [
        "features_pca_train=np.load('features_pca_train_normalized.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ade142d8",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "b122900f",
      "metadata": {},
      "outputs": [
        {
          "ename": "NotFittedError",
          "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[43], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m scaler\u001b[38;5;241m=\u001b[39mStandardScaler()\n\u001b[0;32m      5\u001b[0m pca\u001b[38;5;241m=\u001b[39mPCA(\u001b[38;5;241m1200\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m X_sc_validation \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m features_pca_validation \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mfit(X_sc_validation)\n\u001b[0;32m      8\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures_pca_validation.npy\u001b[39m\u001b[38;5;124m'\u001b[39m,features_pca_validation)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_set_output.py:273\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 273\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    276\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    277\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    278\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    279\u001b[0m         )\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\preprocessing\\_data.py:1040\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform standardization by centering and scaling.\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \n\u001b[0;32m   1028\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;124;03m        Transformed array.\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1040\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m     copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m   1043\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1044\u001b[0m         X,\n\u001b[0;32m   1045\u001b[0m         reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1050\u001b[0m     )\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\validation.py:1544\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1541\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
            "\u001b[1;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "validation_features=np.load(\"test_features_noaugment.npy\")\n",
        "scaler=StandardScaler()\n",
        "pca=PCA(1200)\n",
        "X_sc_validation = scaler.transform(validation_features)\n",
        "features_pca_validation = pca.fit(X_sc_validation)\n",
        "np.save('features_pca_validation.npy',features_pca_validation)\n",
        "y_test = keras.utils.to_categorical(validation_generator.classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "8ea48ecb",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1030, 25088)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_sc_validation.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7517699b",
      "metadata": {
        "id": "7517699b"
      },
      "outputs": [],
      "source": [
        "# Add custom classification layers\n",
        "# x = Flatten()(inception_base.output)\n",
        "# x = Dense(512, activation='relu')(x)\n",
        "# x = Dropout(0.5)(x)\n",
        "# predictions = Dense(num_classes, activation='softmax')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "id": "5f657411",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "5f657411",
        "outputId": "d5ded5d0-a7a2-4264-82e1-d0957c94f881"
      },
      "outputs": [],
      "source": [
        "# # Create the model\n",
        "#model = Model(inputs=vgg_base.input, outputs=predictions)\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "#               loss='categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "584a6951",
      "metadata": {
        "id": "584a6951"
      },
      "outputs": [],
      "source": [
        "#var_name=np.load(filevalue)\n",
        "input=Input(shape=(1200,))\n",
        "x=BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001)(input)\n",
        "x=Dense(256,kernel_regularizer= regularizers.l2(0.016), activity_regularizer= regularizers.l1(0.006),\n",
        "                bias_regularizer= regularizers.l1(0.006),activation='relu')(x)\n",
        "x=Dropout(rate=0.3,seed=42)(x)\n",
        "x=Dense(64,kernel_regularizer= regularizers.l2(0.016), activity_regularizer= regularizers.l1(0.006),\n",
        "                bias_regularizer= regularizers.l1(0.006),activation='relu')(x)\n",
        "x=Dropout(rate=0.3,seed=42)(x)\n",
        "x=Dense(3,kernel_regularizer= regularizers.l2(0.016), activity_regularizer= regularizers.l1(0.006),\n",
        "                bias_regularizer= regularizers.l1(0.006),activation='softmax')(x)\n",
        "model=Model(inputs=input,outputs=x)\n",
        "\n",
        "# Compile the model with adjusted hyperparameters\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy',metrics=['accuracy','recall'])\n",
        "# Adjust the learning rate as needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "f8c766b8",
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath='best_model.keras',\n",
        "    save_best_only=True,\n",
        "    monitor='accuracy',\n",
        "    mode='max'\n",
        ")\n",
        "\n",
        "learning_rate_scheduler_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='accuracy',\n",
        "    patience=3,\n",
        "    factor=0.5,verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "6b59a4da",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.2809 - loss: 39.0908 - recall: 0.2088 - learning_rate: 1.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3328 - loss: 31.7118 - recall: 0.1214 - learning_rate: 1.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3294 - loss: 26.9923 - recall: 0.0437 - learning_rate: 1.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3879 - loss: 21.9238 - recall: 0.0193 - learning_rate: 1.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.3952 - loss: 16.5381 - recall: 0.0097 - learning_rate: 1.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4226 - loss: 12.3060 - recall: 0.0031 - learning_rate: 1.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4569 - loss: 9.6416 - recall: 2.1698e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4766 - loss: 8.0562 - recall: 1.8881e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5021 - loss: 7.0890 - recall: 5.8384e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4924 - loss: 6.3794 - recall: 1.6132e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5049 - loss: 5.8589 - recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5091 - loss: 5.4274 - recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5048 - loss: 5.0777 - recall: 5.8073e-05 - learning_rate: 1.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4978 - loss: 4.7359 - recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m128/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5094 - loss: 4.4355 - recall: 0.0000e+00\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5093 - loss: 4.4343 - recall: 0.0000e+00 - learning_rate: 1.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5229 - loss: 4.1753 - recall: 0.0000e+00 - learning_rate: 5.0000e-05\n",
            "Epoch 17/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5043 - loss: 4.0331 - recall: 0.0000e+00 - learning_rate: 5.0000e-05\n",
            "Epoch 18/200\n",
            "\u001b[1m124/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4970 - loss: 3.9006 - recall: 0.0000e+00\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4972 - loss: 3.8990 - recall: 0.0000e+00 - learning_rate: 5.0000e-05\n",
            "Epoch 19/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4973 - loss: 3.7775 - recall: 0.0000e+00 - learning_rate: 2.5000e-05\n",
            "Epoch 20/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4934 - loss: 3.7050 - recall: 0.0000e+00 - learning_rate: 2.5000e-05\n",
            "Epoch 21/200\n",
            "\u001b[1m127/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5048 - loss: 3.6309 - recall: 0.0000e+00\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5047 - loss: 3.6304 - recall: 0.0000e+00 - learning_rate: 2.5000e-05\n",
            "Epoch 22/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4997 - loss: 3.5656 - recall: 0.0000e+00 - learning_rate: 1.2500e-05\n",
            "Epoch 23/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4946 - loss: 3.5267 - recall: 0.0000e+00 - learning_rate: 1.2500e-05\n",
            "Epoch 24/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4977 - loss: 3.4865 - recall: 0.0000e+00\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4977 - loss: 3.4864 - recall: 0.0000e+00 - learning_rate: 1.2500e-05\n",
            "Epoch 25/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5037 - loss: 3.4476 - recall: 0.0000e+00 - learning_rate: 6.2500e-06\n",
            "Epoch 26/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4993 - loss: 3.4295 - recall: 0.0000e+00 - learning_rate: 6.2500e-06\n",
            "Epoch 27/200\n",
            "\u001b[1m125/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5171 - loss: 3.3995 - recall: 0.0000e+00\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5166 - loss: 3.3995 - recall: 0.0000e+00 - learning_rate: 6.2500e-06\n",
            "Epoch 28/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4985 - loss: 3.3854 - recall: 0.0000e+00 - learning_rate: 3.1250e-06\n",
            "Epoch 29/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4935 - loss: 3.3740 - recall: 0.0000e+00 - learning_rate: 3.1250e-06\n",
            "Epoch 30/200\n",
            "\u001b[1m127/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4896 - loss: 3.3627 - recall: 0.0000e+00\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4899 - loss: 3.3625 - recall: 0.0000e+00 - learning_rate: 3.1250e-06\n",
            "Epoch 31/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5023 - loss: 3.3458 - recall: 0.0000e+00 - learning_rate: 1.5625e-06\n",
            "Epoch 32/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5151 - loss: 3.3362 - recall: 0.0000e+00 - learning_rate: 1.5625e-06\n",
            "Epoch 33/200\n",
            "\u001b[1m122/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5110 - loss: 3.3314 - recall: 0.0000e+00\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5105 - loss: 3.3314 - recall: 0.0000e+00 - learning_rate: 1.5625e-06\n",
            "Epoch 34/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5083 - loss: 3.3248 - recall: 0.0000e+00 - learning_rate: 7.8125e-07\n",
            "Epoch 35/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4938 - loss: 3.3261 - recall: 0.0000e+00 - learning_rate: 7.8125e-07\n",
            "Epoch 36/200\n",
            "\u001b[1m122/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4911 - loss: 3.3201 - recall: 0.0000e+00\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4918 - loss: 3.3199 - recall: 0.0000e+00 - learning_rate: 7.8125e-07\n",
            "Epoch 37/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4923 - loss: 3.3155 - recall: 0.0000e+00 - learning_rate: 3.9062e-07\n",
            "Epoch 38/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5000 - loss: 3.3127 - recall: 0.0000e+00 - learning_rate: 3.9062e-07\n",
            "Epoch 39/200\n",
            "\u001b[1m128/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4998 - loss: 3.3087 - recall: 0.0000e+00\n",
            "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4999 - loss: 3.3087 - recall: 0.0000e+00 - learning_rate: 3.9062e-07\n",
            "Epoch 40/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5031 - loss: 3.3069 - recall: 0.0000e+00 - learning_rate: 1.9531e-07\n",
            "Epoch 41/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5101 - loss: 3.3025 - recall: 0.0000e+00 - learning_rate: 1.9531e-07\n",
            "Epoch 42/200\n",
            "\u001b[1m121/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4969 - loss: 3.3071 - recall: 0.0000e+00\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4972 - loss: 3.3070 - recall: 0.0000e+00 - learning_rate: 1.9531e-07\n",
            "Epoch 43/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5090 - loss: 3.3004 - recall: 0.0000e+00 - learning_rate: 9.7656e-08\n",
            "Epoch 44/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4991 - loss: 3.3039 - recall: 0.0000e+00 - learning_rate: 9.7656e-08\n",
            "Epoch 45/200\n",
            "\u001b[1m123/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5087 - loss: 3.3000 - recall: 0.0000e+00\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5084 - loss: 3.3001 - recall: 0.0000e+00 - learning_rate: 9.7656e-08\n",
            "Epoch 46/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5120 - loss: 3.2996 - recall: 0.0000e+00 - learning_rate: 4.8828e-08\n",
            "Epoch 47/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5076 - loss: 3.3027 - recall: 0.0000e+00 - learning_rate: 4.8828e-08\n",
            "Epoch 48/200\n",
            "\u001b[1m125/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5124 - loss: 3.2976 - recall: 0.0000e+00\n",
            "Epoch 48: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5121 - loss: 3.2978 - recall: 0.0000e+00 - learning_rate: 4.8828e-08\n",
            "Epoch 49/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5016 - loss: 3.3025 - recall: 0.0000e+00 - learning_rate: 2.4414e-08\n",
            "Epoch 50/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4976 - loss: 3.3018 - recall: 0.0000e+00 - learning_rate: 2.4414e-08\n",
            "Epoch 51/200\n",
            "\u001b[1m125/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5123 - loss: 3.2963 - recall: 0.0000e+00\n",
            "Epoch 51: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5119 - loss: 3.2965 - recall: 0.0000e+00 - learning_rate: 2.4414e-08\n",
            "Epoch 52/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4978 - loss: 3.3007 - recall: 0.0000e+00 - learning_rate: 1.2207e-08\n",
            "Epoch 53/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5002 - loss: 3.2996 - recall: 0.0000e+00 - learning_rate: 1.2207e-08\n",
            "Epoch 54/200\n",
            "\u001b[1m118/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5000 - loss: 3.3002 - recall: 0.0000e+00\n",
            "Epoch 54: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5002 - loss: 3.3002 - recall: 0.0000e+00 - learning_rate: 1.2207e-08\n",
            "Epoch 55/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4986 - loss: 3.2998 - recall: 0.0000e+00 - learning_rate: 6.1035e-09\n",
            "Epoch 56/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5009 - loss: 3.3004 - recall: 0.0000e+00 - learning_rate: 6.1035e-09\n",
            "Epoch 57/200\n",
            "\u001b[1m122/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5127 - loss: 3.2977 - recall: 0.0000e+00\n",
            "Epoch 57: ReduceLROnPlateau reducing learning rate to 3.051757735406113e-09.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5121 - loss: 3.2978 - recall: 0.0000e+00 - learning_rate: 6.1035e-09\n",
            "Epoch 58/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5038 - loss: 3.2989 - recall: 0.0000e+00 - learning_rate: 3.0518e-09\n",
            "Epoch 59/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5053 - loss: 3.2979 - recall: 0.0000e+00 - learning_rate: 3.0518e-09\n",
            "Epoch 60/200\n",
            "\u001b[1m125/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4946 - loss: 3.3003 - recall: 0.0000e+00\n",
            "Epoch 60: ReduceLROnPlateau reducing learning rate to 1.5258788677030566e-09.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4949 - loss: 3.3003 - recall: 0.0000e+00 - learning_rate: 3.0518e-09\n",
            "Epoch 61/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5029 - loss: 3.2993 - recall: 0.0000e+00 - learning_rate: 1.5259e-09\n",
            "Epoch 62/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5027 - loss: 3.2993 - recall: 0.0000e+00 - learning_rate: 1.5259e-09\n",
            "Epoch 63/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4897 - loss: 3.3032 - recall: 0.0000e+00\n",
            "Epoch 63: ReduceLROnPlateau reducing learning rate to 7.629394338515283e-10.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4898 - loss: 3.3032 - recall: 0.0000e+00 - learning_rate: 1.5259e-09\n",
            "Epoch 64/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4873 - loss: 3.3068 - recall: 0.0000e+00 - learning_rate: 7.6294e-10\n",
            "Epoch 65/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5138 - loss: 3.2990 - recall: 0.0000e+00 - learning_rate: 7.6294e-10\n",
            "Epoch 66/200\n",
            "\u001b[1m121/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4956 - loss: 3.3015 - recall: 0.0000e+00\n",
            "Epoch 66: ReduceLROnPlateau reducing learning rate to 3.8146971692576415e-10.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4962 - loss: 3.3014 - recall: 0.0000e+00 - learning_rate: 7.6294e-10\n",
            "Epoch 67/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4985 - loss: 3.3007 - recall: 0.0000e+00 - learning_rate: 3.8147e-10\n",
            "Epoch 68/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5023 - loss: 3.3000 - recall: 0.0000e+00 - learning_rate: 3.8147e-10\n",
            "Epoch 69/200\n",
            "\u001b[1m128/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5088 - loss: 3.2976 - recall: 0.0000e+00\n",
            "Epoch 69: ReduceLROnPlateau reducing learning rate to 1.9073485846288207e-10.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5087 - loss: 3.2976 - recall: 0.0000e+00 - learning_rate: 3.8147e-10\n",
            "Epoch 70/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5132 - loss: 3.2960 - recall: 0.0000e+00 - learning_rate: 1.9073e-10\n",
            "Epoch 71/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4890 - loss: 3.3034 - recall: 0.0000e+00 - learning_rate: 1.9073e-10\n",
            "Epoch 72/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5010 - loss: 3.3012 - recall: 0.0000e+00\n",
            "Epoch 72: ReduceLROnPlateau reducing learning rate to 9.536742923144104e-11.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5010 - loss: 3.3012 - recall: 0.0000e+00 - learning_rate: 1.9073e-10\n",
            "Epoch 73/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5082 - loss: 3.2974 - recall: 0.0000e+00 - learning_rate: 9.5367e-11\n",
            "Epoch 74/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4993 - loss: 3.3000 - recall: 0.0000e+00 - learning_rate: 9.5367e-11\n",
            "Epoch 75/200\n",
            "\u001b[1m123/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5136 - loss: 3.2960 - recall: 0.0000e+00\n",
            "Epoch 75: ReduceLROnPlateau reducing learning rate to 4.768371461572052e-11.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5130 - loss: 3.2962 - recall: 0.0000e+00 - learning_rate: 9.5367e-11\n",
            "Epoch 76/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5104 - loss: 3.2984 - recall: 0.0000e+00 - learning_rate: 4.7684e-11\n",
            "Epoch 77/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5043 - loss: 3.2988 - recall: 0.0000e+00 - learning_rate: 4.7684e-11\n",
            "Epoch 78/200\n",
            "\u001b[1m121/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4966 - loss: 3.3030 - recall: 0.0000e+00\n",
            "Epoch 78: ReduceLROnPlateau reducing learning rate to 2.384185730786026e-11.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4969 - loss: 3.3028 - recall: 0.0000e+00 - learning_rate: 4.7684e-11\n",
            "Epoch 79/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5028 - loss: 3.3003 - recall: 0.0000e+00 - learning_rate: 2.3842e-11\n",
            "Epoch 80/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5097 - loss: 3.2964 - recall: 0.0000e+00 - learning_rate: 2.3842e-11\n",
            "Epoch 81/200\n",
            "\u001b[1m121/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5162 - loss: 3.2956 - recall: 0.0000e+00\n",
            "Epoch 81: ReduceLROnPlateau reducing learning rate to 1.192092865393013e-11.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5153 - loss: 3.2958 - recall: 0.0000e+00 - learning_rate: 2.3842e-11\n",
            "Epoch 82/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5075 - loss: 3.2978 - recall: 0.0000e+00 - learning_rate: 1.1921e-11\n",
            "Epoch 83/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4959 - loss: 3.3016 - recall: 0.0000e+00 - learning_rate: 1.1921e-11\n",
            "Epoch 84/200\n",
            "\u001b[1m117/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4837 - loss: 3.3083 - recall: 0.0000e+00\n",
            "Epoch 84: ReduceLROnPlateau reducing learning rate to 5.960464326965065e-12.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4855 - loss: 3.3075 - recall: 0.0000e+00 - learning_rate: 1.1921e-11\n",
            "Epoch 85/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5124 - loss: 3.2974 - recall: 0.0000e+00 - learning_rate: 5.9605e-12\n",
            "Epoch 86/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4953 - loss: 3.3039 - recall: 0.0000e+00 - learning_rate: 5.9605e-12\n",
            "Epoch 87/200\n",
            "\u001b[1m118/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4989 - loss: 3.3010 - recall: 0.0000e+00\n",
            "Epoch 87: ReduceLROnPlateau reducing learning rate to 2.9802321634825324e-12.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4993 - loss: 3.3009 - recall: 0.0000e+00 - learning_rate: 5.9605e-12\n",
            "Epoch 88/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4982 - loss: 3.3017 - recall: 0.0000e+00 - learning_rate: 2.9802e-12\n",
            "Epoch 89/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5165 - loss: 3.2959 - recall: 0.0000e+00 - learning_rate: 2.9802e-12\n",
            "Epoch 90/200\n",
            "\u001b[1m121/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4906 - loss: 3.3027 - recall: 0.0000e+00\n",
            "Epoch 90: ReduceLROnPlateau reducing learning rate to 1.4901160817412662e-12.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4914 - loss: 3.3026 - recall: 0.0000e+00 - learning_rate: 2.9802e-12\n",
            "Epoch 91/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5035 - loss: 3.3004 - recall: 0.0000e+00 - learning_rate: 1.4901e-12\n",
            "Epoch 92/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4987 - loss: 3.2996 - recall: 0.0000e+00 - learning_rate: 1.4901e-12\n",
            "Epoch 93/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5132 - loss: 3.2956 - recall: 0.0000e+00\n",
            "Epoch 93: ReduceLROnPlateau reducing learning rate to 7.450580408706331e-13.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5131 - loss: 3.2956 - recall: 0.0000e+00 - learning_rate: 1.4901e-12\n",
            "Epoch 94/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4959 - loss: 3.3020 - recall: 0.0000e+00 - learning_rate: 7.4506e-13\n",
            "Epoch 95/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4877 - loss: 3.3035 - recall: 0.0000e+00 - learning_rate: 7.4506e-13\n",
            "Epoch 96/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5062 - loss: 3.2986 - recall: 0.0000e+00\n",
            "Epoch 96: ReduceLROnPlateau reducing learning rate to 3.7252902043531655e-13.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5062 - loss: 3.2986 - recall: 0.0000e+00 - learning_rate: 7.4506e-13\n",
            "Epoch 97/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4996 - loss: 3.3018 - recall: 0.0000e+00 - learning_rate: 3.7253e-13\n",
            "Epoch 98/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5090 - loss: 3.2977 - recall: 0.0000e+00 - learning_rate: 3.7253e-13\n",
            "Epoch 99/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4867 - loss: 3.3031 - recall: 0.0000e+00\n",
            "Epoch 99: ReduceLROnPlateau reducing learning rate to 1.8626451021765827e-13.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4868 - loss: 3.3031 - recall: 0.0000e+00 - learning_rate: 3.7253e-13\n",
            "Epoch 100/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4924 - loss: 3.3027 - recall: 0.0000e+00 - learning_rate: 1.8626e-13\n",
            "Epoch 101/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4997 - loss: 3.3004 - recall: 0.0000e+00 - learning_rate: 1.8626e-13\n",
            "Epoch 102/200\n",
            "\u001b[1m128/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4928 - loss: 3.3032 - recall: 0.0000e+00\n",
            "Epoch 102: ReduceLROnPlateau reducing learning rate to 9.313225510882914e-14.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4930 - loss: 3.3031 - recall: 0.0000e+00 - learning_rate: 1.8626e-13\n",
            "Epoch 103/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4971 - loss: 3.3013 - recall: 0.0000e+00 - learning_rate: 9.3132e-14\n",
            "Epoch 104/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5040 - loss: 3.3008 - recall: 0.0000e+00 - learning_rate: 9.3132e-14\n",
            "Epoch 105/200\n",
            "\u001b[1m121/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4924 - loss: 3.3022 - recall: 0.0000e+00\n",
            "Epoch 105: ReduceLROnPlateau reducing learning rate to 4.656612755441457e-14.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4930 - loss: 3.3020 - recall: 0.0000e+00 - learning_rate: 9.3132e-14\n",
            "Epoch 106/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4964 - loss: 3.3036 - recall: 0.0000e+00 - learning_rate: 4.6566e-14\n",
            "Epoch 107/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5040 - loss: 3.2990 - recall: 0.0000e+00 - learning_rate: 4.6566e-14\n",
            "Epoch 108/200\n",
            "\u001b[1m122/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5096 - loss: 3.2987 - recall: 0.0000e+00\n",
            "Epoch 108: ReduceLROnPlateau reducing learning rate to 2.3283063777207284e-14.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5092 - loss: 3.2988 - recall: 0.0000e+00 - learning_rate: 4.6566e-14\n",
            "Epoch 109/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4972 - loss: 3.3000 - recall: 0.0000e+00 - learning_rate: 2.3283e-14\n",
            "Epoch 110/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5074 - loss: 3.2968 - recall: 0.0000e+00 - learning_rate: 2.3283e-14\n",
            "Epoch 111/200\n",
            "\u001b[1m123/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5047 - loss: 3.2998 - recall: 0.0000e+00\n",
            "Epoch 111: ReduceLROnPlateau reducing learning rate to 1.1641531888603642e-14.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5046 - loss: 3.2998 - recall: 0.0000e+00 - learning_rate: 2.3283e-14\n",
            "Epoch 112/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4962 - loss: 3.3023 - recall: 0.0000e+00 - learning_rate: 1.1642e-14\n",
            "Epoch 113/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4916 - loss: 3.3041 - recall: 0.0000e+00 - learning_rate: 1.1642e-14\n",
            "Epoch 114/200\n",
            "\u001b[1m123/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4944 - loss: 3.3039 - recall: 0.0000e+00\n",
            "Epoch 114: ReduceLROnPlateau reducing learning rate to 5.820765944301821e-15.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4948 - loss: 3.3037 - recall: 0.0000e+00 - learning_rate: 1.1642e-14\n",
            "Epoch 115/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5082 - loss: 3.2976 - recall: 0.0000e+00 - learning_rate: 5.8208e-15\n",
            "Epoch 116/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5042 - loss: 3.2993 - recall: 0.0000e+00 - learning_rate: 5.8208e-15\n",
            "Epoch 117/200\n",
            "\u001b[1m125/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4988 - loss: 3.3009 - recall: 0.0000e+00\n",
            "Epoch 117: ReduceLROnPlateau reducing learning rate to 2.9103829721509105e-15.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4989 - loss: 3.3008 - recall: 0.0000e+00 - learning_rate: 5.8208e-15\n",
            "Epoch 118/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4985 - loss: 3.3014 - recall: 0.0000e+00 - learning_rate: 2.9104e-15\n",
            "Epoch 119/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4948 - loss: 3.3033 - recall: 0.0000e+00 - learning_rate: 2.9104e-15\n",
            "Epoch 120/200\n",
            "\u001b[1m118/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4936 - loss: 3.3004 - recall: 0.0000e+00\n",
            "Epoch 120: ReduceLROnPlateau reducing learning rate to 1.4551914860754553e-15.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4942 - loss: 3.3003 - recall: 0.0000e+00 - learning_rate: 2.9104e-15\n",
            "Epoch 121/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5066 - loss: 3.2987 - recall: 0.0000e+00 - learning_rate: 1.4552e-15\n",
            "Epoch 122/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4812 - loss: 3.3051 - recall: 0.0000e+00 - learning_rate: 1.4552e-15\n",
            "Epoch 123/200\n",
            "\u001b[1m119/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5099 - loss: 3.2976 - recall: 0.0000e+00\n",
            "Epoch 123: ReduceLROnPlateau reducing learning rate to 7.275957430377276e-16.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5093 - loss: 3.2978 - recall: 0.0000e+00 - learning_rate: 1.4552e-15\n",
            "Epoch 124/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5059 - loss: 3.2990 - recall: 0.0000e+00 - learning_rate: 7.2760e-16\n",
            "Epoch 125/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4928 - loss: 3.3024 - recall: 0.0000e+00 - learning_rate: 7.2760e-16\n",
            "Epoch 126/200\n",
            "\u001b[1m126/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5087 - loss: 3.2987 - recall: 0.0000e+00\n",
            "Epoch 126: ReduceLROnPlateau reducing learning rate to 3.637978715188638e-16.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5085 - loss: 3.2987 - recall: 0.0000e+00 - learning_rate: 7.2760e-16\n",
            "Epoch 127/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5268 - loss: 3.2915 - recall: 0.0000e+00 - learning_rate: 3.6380e-16\n",
            "Epoch 128/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5024 - loss: 3.2987 - recall: 0.0000e+00 - learning_rate: 3.6380e-16\n",
            "Epoch 129/200\n",
            "\u001b[1m120/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5098 - loss: 3.2972 - recall: 0.0000e+00\n",
            "Epoch 129: ReduceLROnPlateau reducing learning rate to 1.818989357594319e-16.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5092 - loss: 3.2973 - recall: 0.0000e+00 - learning_rate: 3.6380e-16\n",
            "Epoch 130/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5109 - loss: 3.2955 - recall: 0.0000e+00 - learning_rate: 1.8190e-16\n",
            "Epoch 131/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4924 - loss: 3.3010 - recall: 0.0000e+00 - learning_rate: 1.8190e-16\n",
            "Epoch 132/200\n",
            "\u001b[1m128/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5043 - loss: 3.2989 - recall: 0.0000e+00\n",
            "Epoch 132: ReduceLROnPlateau reducing learning rate to 9.094946787971595e-17.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5043 - loss: 3.2989 - recall: 0.0000e+00 - learning_rate: 1.8190e-16\n",
            "Epoch 133/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4910 - loss: 3.3017 - recall: 0.0000e+00 - learning_rate: 9.0949e-17\n",
            "Epoch 134/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5047 - loss: 3.2984 - recall: 0.0000e+00 - learning_rate: 9.0949e-17\n",
            "Epoch 135/200\n",
            "\u001b[1m123/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5012 - loss: 3.3019 - recall: 0.0000e+00\n",
            "Epoch 135: ReduceLROnPlateau reducing learning rate to 4.547473393985798e-17.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5013 - loss: 3.3018 - recall: 0.0000e+00 - learning_rate: 9.0949e-17\n",
            "Epoch 136/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4977 - loss: 3.3007 - recall: 0.0000e+00 - learning_rate: 4.5475e-17\n",
            "Epoch 137/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4991 - loss: 3.3021 - recall: 0.0000e+00 - learning_rate: 4.5475e-17\n",
            "Epoch 138/200\n",
            "\u001b[1m127/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4879 - loss: 3.3029 - recall: 0.0000e+00\n",
            "Epoch 138: ReduceLROnPlateau reducing learning rate to 2.273736696992899e-17.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.4882 - loss: 3.3028 - recall: 0.0000e+00 - learning_rate: 4.5475e-17\n",
            "Epoch 139/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5017 - loss: 3.3008 - recall: 0.0000e+00 - learning_rate: 2.2737e-17\n",
            "Epoch 140/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5090 - loss: 3.2994 - recall: 0.0000e+00 - learning_rate: 2.2737e-17\n",
            "Epoch 141/200\n",
            "\u001b[1m128/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5028 - loss: 3.2995 - recall: 0.0000e+00\n",
            "Epoch 141: ReduceLROnPlateau reducing learning rate to 1.1368683484964494e-17.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5028 - loss: 3.2995 - recall: 0.0000e+00 - learning_rate: 2.2737e-17\n",
            "Epoch 142/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4869 - loss: 3.3033 - recall: 0.0000e+00 - learning_rate: 1.1369e-17\n",
            "Epoch 143/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5158 - loss: 3.2972 - recall: 0.0000e+00 - learning_rate: 1.1369e-17\n",
            "Epoch 144/200\n",
            "\u001b[1m128/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5076 - loss: 3.2984 - recall: 0.0000e+00\n",
            "Epoch 144: ReduceLROnPlateau reducing learning rate to 5.684341742482247e-18.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5075 - loss: 3.2985 - recall: 0.0000e+00 - learning_rate: 1.1369e-17\n",
            "Epoch 145/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5099 - loss: 3.2978 - recall: 0.0000e+00 - learning_rate: 5.6843e-18\n",
            "Epoch 146/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5031 - loss: 3.2991 - recall: 0.0000e+00 - learning_rate: 5.6843e-18\n",
            "Epoch 147/200\n",
            "\u001b[1m122/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5091 - loss: 3.2966 - recall: 0.0000e+00\n",
            "Epoch 147: ReduceLROnPlateau reducing learning rate to 2.8421708712411236e-18.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5088 - loss: 3.2968 - recall: 0.0000e+00 - learning_rate: 5.6843e-18\n",
            "Epoch 148/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4957 - loss: 3.3018 - recall: 0.0000e+00 - learning_rate: 2.8422e-18\n",
            "Epoch 149/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5087 - loss: 3.2983 - recall: 0.0000e+00 - learning_rate: 2.8422e-18\n",
            "Epoch 150/200\n",
            "\u001b[1m122/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5066 - loss: 3.3001 - recall: 0.0000e+00\n",
            "Epoch 150: ReduceLROnPlateau reducing learning rate to 1.4210854356205618e-18.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5064 - loss: 3.3001 - recall: 0.0000e+00 - learning_rate: 2.8422e-18\n",
            "Epoch 151/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4933 - loss: 3.3021 - recall: 0.0000e+00 - learning_rate: 1.4211e-18\n",
            "Epoch 152/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5102 - loss: 3.2997 - recall: 0.0000e+00 - learning_rate: 1.4211e-18\n",
            "Epoch 153/200\n",
            "\u001b[1m120/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4963 - loss: 3.3036 - recall: 0.0000e+00\n",
            "Epoch 153: ReduceLROnPlateau reducing learning rate to 7.105427178102809e-19.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4968 - loss: 3.3033 - recall: 0.0000e+00 - learning_rate: 1.4211e-18\n",
            "Epoch 154/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5195 - loss: 3.2945 - recall: 0.0000e+00 - learning_rate: 7.1054e-19\n",
            "Epoch 155/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4869 - loss: 3.3032 - recall: 0.0000e+00 - learning_rate: 7.1054e-19\n",
            "Epoch 156/200\n",
            "\u001b[1m128/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4986 - loss: 3.3034 - recall: 0.0000e+00\n",
            "Epoch 156: ReduceLROnPlateau reducing learning rate to 3.5527135890514045e-19.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4987 - loss: 3.3033 - recall: 0.0000e+00 - learning_rate: 7.1054e-19\n",
            "Epoch 157/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5088 - loss: 3.2967 - recall: 0.0000e+00 - learning_rate: 3.5527e-19\n",
            "Epoch 158/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5040 - loss: 3.3012 - recall: 0.0000e+00 - learning_rate: 3.5527e-19\n",
            "Epoch 159/200\n",
            "\u001b[1m128/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5021 - loss: 3.2991 - recall: 0.0000e+00\n",
            "Epoch 159: ReduceLROnPlateau reducing learning rate to 1.7763567945257022e-19.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5021 - loss: 3.2991 - recall: 0.0000e+00 - learning_rate: 3.5527e-19\n",
            "Epoch 160/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5053 - loss: 3.2997 - recall: 0.0000e+00 - learning_rate: 1.7764e-19\n",
            "Epoch 161/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4949 - loss: 3.3035 - recall: 0.0000e+00 - learning_rate: 1.7764e-19\n",
            "Epoch 162/200\n",
            "\u001b[1m124/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5148 - loss: 3.2944 - recall: 0.0000e+00\n",
            "Epoch 162: ReduceLROnPlateau reducing learning rate to 8.881783972628511e-20.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5142 - loss: 3.2946 - recall: 0.0000e+00 - learning_rate: 1.7764e-19\n",
            "Epoch 163/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5009 - loss: 3.2983 - recall: 0.0000e+00 - learning_rate: 8.8818e-20\n",
            "Epoch 164/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5039 - loss: 3.2980 - recall: 0.0000e+00 - learning_rate: 8.8818e-20\n",
            "Epoch 165/200\n",
            "\u001b[1m125/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5086 - loss: 3.2977 - recall: 0.0000e+00\n",
            "Epoch 165: ReduceLROnPlateau reducing learning rate to 4.4408919863142556e-20.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5083 - loss: 3.2978 - recall: 0.0000e+00 - learning_rate: 8.8818e-20\n",
            "Epoch 166/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5043 - loss: 3.3005 - recall: 0.0000e+00 - learning_rate: 4.4409e-20\n",
            "Epoch 167/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5067 - loss: 3.2987 - recall: 0.0000e+00 - learning_rate: 4.4409e-20\n",
            "Epoch 168/200\n",
            "\u001b[1m125/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5039 - loss: 3.2991 - recall: 0.0000e+00\n",
            "Epoch 168: ReduceLROnPlateau reducing learning rate to 2.2204459931571278e-20.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5039 - loss: 3.2991 - recall: 0.0000e+00 - learning_rate: 4.4409e-20\n",
            "Epoch 169/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5023 - loss: 3.2981 - recall: 0.0000e+00 - learning_rate: 2.2204e-20\n",
            "Epoch 170/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5089 - loss: 3.2997 - recall: 0.0000e+00 - learning_rate: 2.2204e-20\n",
            "Epoch 171/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5136 - loss: 3.2950 - recall: 0.0000e+00\n",
            "Epoch 171: ReduceLROnPlateau reducing learning rate to 1.1102229965785639e-20.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5135 - loss: 3.2951 - recall: 0.0000e+00 - learning_rate: 2.2204e-20\n",
            "Epoch 172/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4990 - loss: 3.2999 - recall: 0.0000e+00 - learning_rate: 1.1102e-20\n",
            "Epoch 173/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5095 - loss: 3.2982 - recall: 0.0000e+00 - learning_rate: 1.1102e-20\n",
            "Epoch 174/200\n",
            "\u001b[1m123/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5007 - loss: 3.3010 - recall: 0.0000e+00\n",
            "Epoch 174: ReduceLROnPlateau reducing learning rate to 5.5511149828928195e-21.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5008 - loss: 3.3009 - recall: 0.0000e+00 - learning_rate: 1.1102e-20\n",
            "Epoch 175/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5047 - loss: 3.2991 - recall: 0.0000e+00 - learning_rate: 5.5511e-21\n",
            "Epoch 176/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4951 - loss: 3.3009 - recall: 0.0000e+00 - learning_rate: 5.5511e-21\n",
            "Epoch 177/200\n",
            "\u001b[1m127/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5019 - loss: 3.3031 - recall: 0.0000e+00\n",
            "Epoch 177: ReduceLROnPlateau reducing learning rate to 2.7755574914464097e-21.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5019 - loss: 3.3031 - recall: 0.0000e+00 - learning_rate: 5.5511e-21\n",
            "Epoch 178/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5102 - loss: 3.2961 - recall: 0.0000e+00 - learning_rate: 2.7756e-21\n",
            "Epoch 179/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4964 - loss: 3.3010 - recall: 0.0000e+00 - learning_rate: 2.7756e-21\n",
            "Epoch 180/200\n",
            "\u001b[1m118/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4924 - loss: 3.3029 - recall: 0.0000e+00\n",
            "Epoch 180: ReduceLROnPlateau reducing learning rate to 1.3877787457232049e-21.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4932 - loss: 3.3026 - recall: 0.0000e+00 - learning_rate: 2.7756e-21\n",
            "Epoch 181/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5128 - loss: 3.2963 - recall: 0.0000e+00 - learning_rate: 1.3878e-21\n",
            "Epoch 182/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5016 - loss: 3.2982 - recall: 0.0000e+00 - learning_rate: 1.3878e-21\n",
            "Epoch 183/200\n",
            "\u001b[1m119/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5005 - loss: 3.2986 - recall: 0.0000e+00\n",
            "Epoch 183: ReduceLROnPlateau reducing learning rate to 6.938893728616024e-22.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5007 - loss: 3.2987 - recall: 0.0000e+00 - learning_rate: 1.3878e-21\n",
            "Epoch 184/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.4967 - loss: 3.3020 - recall: 0.0000e+00 - learning_rate: 6.9389e-22\n",
            "Epoch 185/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5046 - loss: 3.2989 - recall: 0.0000e+00 - learning_rate: 6.9389e-22\n",
            "Epoch 186/200\n",
            "\u001b[1m122/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4987 - loss: 3.3009 - recall: 0.0000e+00\n",
            "Epoch 186: ReduceLROnPlateau reducing learning rate to 3.469446864308012e-22.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4990 - loss: 3.3008 - recall: 0.0000e+00 - learning_rate: 6.9389e-22\n",
            "Epoch 187/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5100 - loss: 3.2968 - recall: 0.0000e+00 - learning_rate: 3.4694e-22\n",
            "Epoch 188/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5071 - loss: 3.2993 - recall: 0.0000e+00 - learning_rate: 3.4694e-22\n",
            "Epoch 189/200\n",
            "\u001b[1m123/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5113 - loss: 3.2965 - recall: 0.0000e+00\n",
            "Epoch 189: ReduceLROnPlateau reducing learning rate to 1.734723432154006e-22.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5108 - loss: 3.2966 - recall: 0.0000e+00 - learning_rate: 3.4694e-22\n",
            "Epoch 190/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4938 - loss: 3.3010 - recall: 0.0000e+00 - learning_rate: 1.7347e-22\n",
            "Epoch 191/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5088 - loss: 3.2985 - recall: 0.0000e+00 - learning_rate: 1.7347e-22\n",
            "Epoch 192/200\n",
            "\u001b[1m127/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4998 - loss: 3.3028 - recall: 0.0000e+00\n",
            "Epoch 192: ReduceLROnPlateau reducing learning rate to 8.67361716077003e-23.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4998 - loss: 3.3027 - recall: 0.0000e+00 - learning_rate: 1.7347e-22\n",
            "Epoch 193/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4995 - loss: 3.2990 - recall: 0.0000e+00 - learning_rate: 8.6736e-23\n",
            "Epoch 194/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5153 - loss: 3.2957 - recall: 0.0000e+00 - learning_rate: 8.6736e-23\n",
            "Epoch 195/200\n",
            "\u001b[1m126/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5085 - loss: 3.2973 - recall: 0.0000e+00\n",
            "Epoch 195: ReduceLROnPlateau reducing learning rate to 4.336808580385015e-23.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5083 - loss: 3.2974 - recall: 0.0000e+00 - learning_rate: 8.6736e-23\n",
            "Epoch 196/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5015 - loss: 3.3012 - recall: 0.0000e+00 - learning_rate: 4.3368e-23\n",
            "Epoch 197/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5073 - loss: 3.2982 - recall: 0.0000e+00 - learning_rate: 4.3368e-23\n",
            "Epoch 198/200\n",
            "\u001b[1m128/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4981 - loss: 3.3006 - recall: 0.0000e+00\n",
            "Epoch 198: ReduceLROnPlateau reducing learning rate to 2.1684042901925076e-23.\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4982 - loss: 3.3005 - recall: 0.0000e+00 - learning_rate: 4.3368e-23\n",
            "Epoch 199/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.4895 - loss: 3.3025 - recall: 0.0000e+00 - learning_rate: 2.1684e-23\n",
            "Epoch 200/200\n",
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5052 - loss: 3.3007 - recall: 0.0000e+00 - learning_rate: 2.1684e-23\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x13d23ee6150>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(features_pca_train, y_train, epochs=200, batch_size=32, callbacks = [checkpoint_callback,learning_rate_scheduler_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "ff15daed",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4124, 1200)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features_pca_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "id": "7b2f9159",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.3316 - loss: 2.3789 - recall: 0.2930\n",
            "Epoch 2/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3541 - loss: 1.2631 - recall: 0.1814\n",
            "Epoch 3/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3418 - loss: 1.1646 - recall: 0.0820\n",
            "Epoch 4/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3424 - loss: 1.1260 - recall: 0.0432\n",
            "Epoch 5/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3598 - loss: 1.1150 - recall: 0.0294\n",
            "Epoch 6/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3498 - loss: 1.1048 - recall: 0.0209\n",
            "Epoch 7/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3550 - loss: 1.1016 - recall: 0.0148\n",
            "Epoch 8/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3518 - loss: 1.0997 - recall: 0.0128\n",
            "Epoch 9/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3585 - loss: 1.0984 - recall: 0.0170\n",
            "Epoch 10/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3578 - loss: 1.0973 - recall: 0.0140\n",
            "Epoch 11/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3708 - loss: 1.0947 - recall: 0.0146\n",
            "Epoch 12/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3646 - loss: 1.0927 - recall: 0.0218\n",
            "Epoch 13/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3697 - loss: 1.0918 - recall: 0.0249\n",
            "Epoch 14/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3790 - loss: 1.0838 - recall: 0.0272\n",
            "Epoch 15/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.3955 - loss: 1.0821 - recall: 0.0428\n",
            "Epoch 16/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4101 - loss: 1.0695 - recall: 0.0632\n",
            "Epoch 17/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4212 - loss: 1.0631 - recall: 0.0858\n",
            "Epoch 18/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4382 - loss: 1.0486 - recall: 0.1076\n",
            "Epoch 19/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4510 - loss: 1.0365 - recall: 0.1366\n",
            "Epoch 20/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4593 - loss: 1.0212 - recall: 0.1544\n",
            "Epoch 21/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.4750 - loss: 1.0113 - recall: 0.1828\n",
            "Epoch 22/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4822 - loss: 0.9997 - recall: 0.2035\n",
            "Epoch 23/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4921 - loss: 0.9883 - recall: 0.2206\n",
            "Epoch 24/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5068 - loss: 0.9758 - recall: 0.2391\n",
            "Epoch 25/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5251 - loss: 0.9517 - recall: 0.2729\n",
            "Epoch 26/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5155 - loss: 0.9504 - recall: 0.2713\n",
            "Epoch 27/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5291 - loss: 0.9378 - recall: 0.2938\n",
            "Epoch 28/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5465 - loss: 0.9294 - recall: 0.3133\n",
            "Epoch 29/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5525 - loss: 0.9246 - recall: 0.3193\n",
            "Epoch 30/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5568 - loss: 0.9001 - recall: 0.3386\n",
            "Epoch 31/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5584 - loss: 0.8982 - recall: 0.3468\n",
            "Epoch 32/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5642 - loss: 0.8827 - recall: 0.3611\n",
            "Epoch 33/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5612 - loss: 0.8882 - recall: 0.3546\n",
            "Epoch 34/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5784 - loss: 0.8652 - recall: 0.3811\n",
            "Epoch 35/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5829 - loss: 0.8606 - recall: 0.3812\n",
            "Epoch 36/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5759 - loss: 0.8486 - recall: 0.3914\n",
            "Epoch 37/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5835 - loss: 0.8429 - recall: 0.3942\n",
            "Epoch 38/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5970 - loss: 0.8264 - recall: 0.4189\n",
            "Epoch 39/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5907 - loss: 0.8311 - recall: 0.4031\n",
            "Epoch 40/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5995 - loss: 0.8176 - recall: 0.4228\n",
            "Epoch 41/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5902 - loss: 0.8204 - recall: 0.4284\n",
            "Epoch 42/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6030 - loss: 0.8101 - recall: 0.4284\n",
            "Epoch 43/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6035 - loss: 0.7993 - recall: 0.4324\n",
            "Epoch 44/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5998 - loss: 0.7994 - recall: 0.4409\n",
            "Epoch 45/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6025 - loss: 0.7961 - recall: 0.4405\n",
            "Epoch 46/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6142 - loss: 0.7704 - recall: 0.4603\n",
            "Epoch 47/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6027 - loss: 0.7749 - recall: 0.4427\n",
            "Epoch 48/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6102 - loss: 0.7669 - recall: 0.4574\n",
            "Epoch 49/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6157 - loss: 0.7656 - recall: 0.4650\n",
            "Epoch 50/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6155 - loss: 0.7561 - recall: 0.4606\n",
            "Epoch 51/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6111 - loss: 0.7580 - recall: 0.4529\n",
            "Epoch 52/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6331 - loss: 0.7271 - recall: 0.4848\n",
            "Epoch 53/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6243 - loss: 0.7399 - recall: 0.4719\n",
            "Epoch 54/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6303 - loss: 0.7289 - recall: 0.4839\n",
            "Epoch 55/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6221 - loss: 0.7337 - recall: 0.4719\n",
            "Epoch 56/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6245 - loss: 0.7237 - recall: 0.4805\n",
            "Epoch 57/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6242 - loss: 0.7209 - recall: 0.4767\n",
            "Epoch 58/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6416 - loss: 0.7048 - recall: 0.5002\n",
            "Epoch 59/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6438 - loss: 0.7034 - recall: 0.5022\n",
            "Epoch 60/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6354 - loss: 0.6984 - recall: 0.4989\n",
            "Epoch 61/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6506 - loss: 0.6828 - recall: 0.5069\n",
            "Epoch 62/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6378 - loss: 0.6940 - recall: 0.4997\n",
            "Epoch 63/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6475 - loss: 0.6826 - recall: 0.5034\n",
            "Epoch 64/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6403 - loss: 0.6860 - recall: 0.5025\n",
            "Epoch 65/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6410 - loss: 0.6797 - recall: 0.5085\n",
            "Epoch 66/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6507 - loss: 0.6762 - recall: 0.5073\n",
            "Epoch 67/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6429 - loss: 0.6732 - recall: 0.5078\n",
            "Epoch 68/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6469 - loss: 0.6735 - recall: 0.5136\n",
            "Epoch 69/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6565 - loss: 0.6627 - recall: 0.5238\n",
            "Epoch 70/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6479 - loss: 0.6610 - recall: 0.5140\n",
            "Epoch 71/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6534 - loss: 0.6545 - recall: 0.5247\n",
            "Epoch 72/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6512 - loss: 0.6453 - recall: 0.5231\n",
            "Epoch 73/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6544 - loss: 0.6469 - recall: 0.5216\n",
            "Epoch 74/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6537 - loss: 0.6519 - recall: 0.5236\n",
            "Epoch 75/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6674 - loss: 0.6302 - recall: 0.5318\n",
            "Epoch 76/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6521 - loss: 0.6348 - recall: 0.5268\n",
            "Epoch 77/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6494 - loss: 0.6415 - recall: 0.5228\n",
            "Epoch 78/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6549 - loss: 0.6324 - recall: 0.5318\n",
            "Epoch 79/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6674 - loss: 0.6262 - recall: 0.5480\n",
            "Epoch 80/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6600 - loss: 0.6187 - recall: 0.5420\n",
            "Epoch 81/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6635 - loss: 0.6189 - recall: 0.5464\n",
            "Epoch 82/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6698 - loss: 0.6152 - recall: 0.5414\n",
            "Epoch 83/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6667 - loss: 0.6255 - recall: 0.5405\n",
            "Epoch 84/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6563 - loss: 0.6194 - recall: 0.5391\n",
            "Epoch 85/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6624 - loss: 0.6140 - recall: 0.5449\n",
            "Epoch 86/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6585 - loss: 0.6133 - recall: 0.5396\n",
            "Epoch 87/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6611 - loss: 0.6192 - recall: 0.5390\n",
            "Epoch 88/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6718 - loss: 0.6079 - recall: 0.5534\n",
            "Epoch 89/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6541 - loss: 0.6132 - recall: 0.5321\n",
            "Epoch 90/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6612 - loss: 0.6150 - recall: 0.5440\n",
            "Epoch 91/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6669 - loss: 0.6077 - recall: 0.5510\n",
            "Epoch 92/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6718 - loss: 0.5980 - recall: 0.5588\n",
            "Epoch 93/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6813 - loss: 0.5944 - recall: 0.5684\n",
            "Epoch 94/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6717 - loss: 0.5983 - recall: 0.5533\n",
            "Epoch 95/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6763 - loss: 0.5943 - recall: 0.5532\n",
            "Epoch 96/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6683 - loss: 0.5913 - recall: 0.5612\n",
            "Epoch 97/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6833 - loss: 0.5865 - recall: 0.5689\n",
            "Epoch 98/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6714 - loss: 0.5916 - recall: 0.5566\n",
            "Epoch 99/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6718 - loss: 0.5857 - recall: 0.5578\n",
            "Epoch 100/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6701 - loss: 0.5925 - recall: 0.5520\n",
            "Epoch 101/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6791 - loss: 0.5928 - recall: 0.5638\n",
            "Epoch 102/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6664 - loss: 0.5833 - recall: 0.5629\n",
            "Epoch 103/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6798 - loss: 0.5853 - recall: 0.5658\n",
            "Epoch 104/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6713 - loss: 0.5883 - recall: 0.5540\n",
            "Epoch 105/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6719 - loss: 0.5926 - recall: 0.5624\n",
            "Epoch 106/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6672 - loss: 0.5833 - recall: 0.5562\n",
            "Epoch 107/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6643 - loss: 0.5880 - recall: 0.5592\n",
            "Epoch 108/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6684 - loss: 0.5842 - recall: 0.5588\n",
            "Epoch 109/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6802 - loss: 0.5714 - recall: 0.5711\n",
            "Epoch 110/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6735 - loss: 0.5799 - recall: 0.5686\n",
            "Epoch 111/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6792 - loss: 0.5736 - recall: 0.5708\n",
            "Epoch 112/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6734 - loss: 0.5802 - recall: 0.5616\n",
            "Epoch 113/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6708 - loss: 0.5748 - recall: 0.5622\n",
            "Epoch 114/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6804 - loss: 0.5745 - recall: 0.5701\n",
            "Epoch 115/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6823 - loss: 0.5694 - recall: 0.5793\n",
            "Epoch 116/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6757 - loss: 0.5616 - recall: 0.5723\n",
            "Epoch 117/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6794 - loss: 0.5630 - recall: 0.5773\n",
            "Epoch 118/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6809 - loss: 0.5695 - recall: 0.5783\n",
            "Epoch 119/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6843 - loss: 0.5618 - recall: 0.5842\n",
            "Epoch 120/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6809 - loss: 0.5689 - recall: 0.5741\n",
            "Epoch 121/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6737 - loss: 0.5655 - recall: 0.5702\n",
            "Epoch 122/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6850 - loss: 0.5630 - recall: 0.5777\n",
            "Epoch 123/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6740 - loss: 0.5768 - recall: 0.5736\n",
            "Epoch 124/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6734 - loss: 0.5625 - recall: 0.5742\n",
            "Epoch 125/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6791 - loss: 0.5619 - recall: 0.5743\n",
            "Epoch 126/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6778 - loss: 0.5675 - recall: 0.5728\n",
            "Epoch 127/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6849 - loss: 0.5607 - recall: 0.5811\n",
            "Epoch 128/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6872 - loss: 0.5478 - recall: 0.5877\n",
            "Epoch 129/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6839 - loss: 0.5521 - recall: 0.5853\n",
            "Epoch 130/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6687 - loss: 0.5725 - recall: 0.5621\n",
            "Epoch 131/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6764 - loss: 0.5679 - recall: 0.5734\n",
            "Epoch 132/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6821 - loss: 0.5594 - recall: 0.5777\n",
            "Epoch 133/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6804 - loss: 0.5576 - recall: 0.5771\n",
            "Epoch 134/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6803 - loss: 0.5621 - recall: 0.5756\n",
            "Epoch 135/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6806 - loss: 0.5493 - recall: 0.5831\n",
            "Epoch 136/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6865 - loss: 0.5508 - recall: 0.5823\n",
            "Epoch 137/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6728 - loss: 0.5568 - recall: 0.5737\n",
            "Epoch 138/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6824 - loss: 0.5543 - recall: 0.5835\n",
            "Epoch 139/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6889 - loss: 0.5430 - recall: 0.5918\n",
            "Epoch 140/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6844 - loss: 0.5490 - recall: 0.5858\n",
            "Epoch 141/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6907 - loss: 0.5431 - recall: 0.5973\n",
            "Epoch 142/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6769 - loss: 0.5477 - recall: 0.5797\n",
            "Epoch 143/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6832 - loss: 0.5491 - recall: 0.5853\n",
            "Epoch 144/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6859 - loss: 0.5563 - recall: 0.5862\n",
            "Epoch 145/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6803 - loss: 0.5535 - recall: 0.5831\n",
            "Epoch 146/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6916 - loss: 0.5447 - recall: 0.5943\n",
            "Epoch 147/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6887 - loss: 0.5439 - recall: 0.5844\n",
            "Epoch 148/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6833 - loss: 0.5457 - recall: 0.5835\n",
            "Epoch 149/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6854 - loss: 0.5487 - recall: 0.5888\n",
            "Epoch 150/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6892 - loss: 0.5378 - recall: 0.5993\n",
            "Epoch 151/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6938 - loss: 0.5367 - recall: 0.5957\n",
            "Epoch 152/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6919 - loss: 0.5508 - recall: 0.5937\n",
            "Epoch 153/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6836 - loss: 0.5446 - recall: 0.5913\n",
            "Epoch 154/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6896 - loss: 0.5409 - recall: 0.5937\n",
            "Epoch 155/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6829 - loss: 0.5435 - recall: 0.5929\n",
            "Epoch 156/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6977 - loss: 0.5407 - recall: 0.6014\n",
            "Epoch 157/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6903 - loss: 0.5351 - recall: 0.5976\n",
            "Epoch 158/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6820 - loss: 0.5418 - recall: 0.5863\n",
            "Epoch 159/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6935 - loss: 0.5351 - recall: 0.5988\n",
            "Epoch 160/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6908 - loss: 0.5398 - recall: 0.5944\n",
            "Epoch 161/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6992 - loss: 0.5273 - recall: 0.6077\n",
            "Epoch 162/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6915 - loss: 0.5452 - recall: 0.5989\n",
            "Epoch 163/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6867 - loss: 0.5321 - recall: 0.5949\n",
            "Epoch 164/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6881 - loss: 0.5374 - recall: 0.5933\n",
            "Epoch 165/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6905 - loss: 0.5331 - recall: 0.5976\n",
            "Epoch 166/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6880 - loss: 0.5357 - recall: 0.5926\n",
            "Epoch 167/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6837 - loss: 0.5457 - recall: 0.5923\n",
            "Epoch 168/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6909 - loss: 0.5345 - recall: 0.5928\n",
            "Epoch 169/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6828 - loss: 0.5513 - recall: 0.5856\n",
            "Epoch 170/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6923 - loss: 0.5330 - recall: 0.6066\n",
            "Epoch 171/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6829 - loss: 0.5331 - recall: 0.5906\n",
            "Epoch 172/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7018 - loss: 0.5247 - recall: 0.6106\n",
            "Epoch 173/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6959 - loss: 0.5285 - recall: 0.6054\n",
            "Epoch 174/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6903 - loss: 0.5387 - recall: 0.5949\n",
            "Epoch 175/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6884 - loss: 0.5343 - recall: 0.6016\n",
            "Epoch 176/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6880 - loss: 0.5320 - recall: 0.5981\n",
            "Epoch 177/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6919 - loss: 0.5292 - recall: 0.5993\n",
            "Epoch 178/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6883 - loss: 0.5277 - recall: 0.5962\n",
            "Epoch 179/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6993 - loss: 0.5247 - recall: 0.6101\n",
            "Epoch 180/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6880 - loss: 0.5301 - recall: 0.6022\n",
            "Epoch 181/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7020 - loss: 0.5308 - recall: 0.6102\n",
            "Epoch 182/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6930 - loss: 0.5284 - recall: 0.6022\n",
            "Epoch 183/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7001 - loss: 0.5208 - recall: 0.6118\n",
            "Epoch 184/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6981 - loss: 0.5258 - recall: 0.6120\n",
            "Epoch 185/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6881 - loss: 0.5253 - recall: 0.5994\n",
            "Epoch 186/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6939 - loss: 0.5217 - recall: 0.6033\n",
            "Epoch 187/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6961 - loss: 0.5252 - recall: 0.6096\n",
            "Epoch 188/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6947 - loss: 0.5260 - recall: 0.6047\n",
            "Epoch 189/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7001 - loss: 0.5259 - recall: 0.6084\n",
            "Epoch 190/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7015 - loss: 0.5268 - recall: 0.6083\n",
            "Epoch 191/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6952 - loss: 0.5217 - recall: 0.6059\n",
            "Epoch 192/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6993 - loss: 0.5261 - recall: 0.6111\n",
            "Epoch 193/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6861 - loss: 0.5342 - recall: 0.5960\n",
            "Epoch 194/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6947 - loss: 0.5256 - recall: 0.6050\n",
            "Epoch 195/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7015 - loss: 0.5279 - recall: 0.6100\n",
            "Epoch 196/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.6948 - loss: 0.5227 - recall: 0.6036\n",
            "Epoch 197/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6965 - loss: 0.5264 - recall: 0.6141\n",
            "Epoch 198/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6990 - loss: 0.5172 - recall: 0.6157\n",
            "Epoch 199/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.6941 - loss: 0.5239 - recall: 0.6067\n",
            "Epoch 200/200\n",
            "\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7009 - loss: 0.5168 - recall: 0.6139\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x2de438e3dd0>"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#model.fit(features_pca_train,y_train,epochs=200,batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "12a2fd92",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12a2fd92",
        "outputId": "d2217ffc-6f50-4dee-8fc3-1b774ab0c7e9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1200</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1200</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,800</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">307,456</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1200\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1200\u001b[0m)           │         \u001b[38;5;34m4,800\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m307,456\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">981,899</span> (3.75 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m981,899\u001b[0m (3.75 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">326,499</span> (1.25 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m326,499\u001b[0m (1.25 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,400</span> (9.38 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,400\u001b[0m (9.38 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">653,000</span> (2.49 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m653,000\u001b[0m (2.49 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Print model summary for debugging\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "22b923fd",
      "metadata": {
        "id": "22b923fd"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Input 0 of layer \"functional_1\" is incompatible with the layer: expected shape=(None, 1200), found shape=(32, 1030)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[39], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_score, recall_score, f1_score\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Predict classes for the validation set\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m validation_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_pca_validation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Convert probabilities to class labels\u001b[39;00m\n\u001b[0;32m      7\u001b[0m predicted_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(validation_predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\input_spec.py:245\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[1;32m--> 245\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    246\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m         )\n",
            "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"functional_1\" is incompatible with the layer: expected shape=(None, 1200), found shape=(32, 1030)"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Predict classes for the validation set\n",
        "validation_predictions = model.predict(features_pca_validation)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "predicted_classes = np.argmax(validation_predictions, axis=1)\n",
        "\n",
        "# Get true class labels\n",
        "true_classes = validation_generator.classes\n",
        "\n",
        "# Calculate precision\n",
        "precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faad546b",
      "metadata": {},
      "source": [
        "The _new file as of now has the model and precision and recall for the images with noise and blur\n",
        "Save it into a new file if making any changes so that the model can be evaluated easily"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8451ca9b",
      "metadata": {
        "id": "8451ca9b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
